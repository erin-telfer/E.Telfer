{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Water Observations from Space (WOfS) for flow percentiles of HRS stream gauges (automated retrieval from BoM)¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates a flow duration curve (FDC) and examines Water Observation from Space (WOfS) for specified flow percentage exceedance ranges. Additionally, WOfS can be used to examine inbank and overbank streamflow.\n",
    "\n",
    "Daily streamflow information and stream gauge coordinates are retrieved directly from the Bureau of Meteorology (BoM) Hydrologic Reference Stations (HRS) website, http://www.bom.gov.au/water/hrs/. Streamflow data is used to calculate the percentage exceedance statistic (the percentage of time that the streamflow value is equalled or exceeded by all other streamflow values within the data set).\n",
    "\n",
    "The date of streamflow measurement and date of available satellite imagery are matched, for the location of the gauge. A flow duration curve plot is created. The user can specify a percentile range of interest and an image is created that shows the percentage of time that water is present (or absent) around the stream gauge, during the specified percentile range of interest. \n",
    "\n",
    "Finally the number of pixels that contain water, within each scene, are counted and plotted against percentage exceedance for that scene. This plot can be used to eyeball where/if the amount of the water on the ground increases dramatically, and therefore be used to estimate the point where flow extends over and past the streambank. \n",
    "\n",
    "\"###\" indicates fields that require user modification.\n",
    "\n",
    "\"##\" indicates fields that may require user modification, e.g. graphic edits/preferences.\n",
    "\n",
    "\"#\" indicates a cell title or description of code. No modification is required.\n",
    "\n",
    "Code written in May 2017 by Erin Telfer with support from Leo Lymburner, Damien Ayers and Biswajit Bala.\n",
    "\n",
    "The notebook was completed as a graduate program project at Geoscience Australia. If you find an error or if you have any suggestions, please contact erin.telfer@ga.gov.au. Alternatively, please contact leo.lymburner@ga.gov.au."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-09T11:09:06.502514",
     "start_time": "2016-06-09T11:09:04.805211"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "%pylab notebook\n",
    "\n",
    "import datacube \n",
    "from datacube import Datacube\n",
    "from datacube.storage import masking\n",
    "from datacube.storage.masking import mask_to_dict\n",
    "from datacube.storage.storage import write_dataset_to_netcdf\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import rasterio\n",
    "from pyproj import Proj, transform\n",
    "import urllib\n",
    "from dateutil import tz\n",
    "from_zone = tz.tzutc()\n",
    "to_zone = tz.tzlocal()\n",
    "dc = datacube.Datacube(app='dc-show changes in annual mean NDVI values')\n",
    "dcwofs = Datacube(config='/g/data/r78/ext547/wofscube.conf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve stream data and coordinates from the BoM website\n",
    "The URL for the data is set using the gauge_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Specify stream gauge of interest.\n",
    "\n",
    "###User modification: Enter the ID code for the gauge of interest. ID code can be viewed on \n",
    "###http://www.bom.gov.au/water/hrs/ e.g. for 'Diamantina River at Birdsville' the ID code is 'A0020101'\n",
    "\n",
    "gauge_of_interest= 'G9030250'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date     Flow (ML) Bureau QCode\n",
      "0      1966-08-13     10.290800            E\n",
      "1      1966-08-14     10.009100            E\n",
      "2      1966-08-15      9.956920            E\n",
      "3      1966-08-16      9.579110            E\n",
      "4      1966-08-17      9.292170            E\n",
      "5      1966-08-18      9.196090            E\n",
      "6      1966-08-19      9.297820            E\n",
      "7      1966-08-20      9.863880            E\n",
      "8      1966-08-21      6.381870            E\n",
      "9      1966-08-22      4.254020            E\n",
      "10     1966-08-23      3.432010            E\n",
      "11     1966-08-24      3.303020            E\n",
      "12     1966-08-25      3.264020            E\n",
      "13     1966-08-26      3.299020            E\n",
      "14     1966-08-27      3.275020            E\n",
      "15     1966-08-28      3.240020            E\n",
      "16     1966-08-29      3.239020            E\n",
      "17     1966-08-30      3.120980            E\n",
      "18     1966-08-31      2.600010            E\n",
      "19     1966-09-01      1.805000            E\n",
      "20     1966-09-02      1.603010            E\n",
      "21     1966-09-03      1.446020            E\n",
      "22     1966-09-04      1.173990            E\n",
      "23     1966-09-05      0.737009            E\n",
      "24     1966-09-06      0.496020            E\n",
      "25     1966-09-07      0.362000            E\n",
      "26     1966-09-08      0.220998            E\n",
      "27     1966-09-09      0.095000            E\n",
      "28     1966-09-10      0.033000            E\n",
      "29     1966-09-11      0.000000            E\n",
      "...           ...           ...          ...\n",
      "17643  2014-12-02    158.923000            E\n",
      "17644  2014-12-03    150.693000            E\n",
      "17645  2014-12-04    158.023000            E\n",
      "17646  2014-12-05    179.252000            E\n",
      "17647  2014-12-06    212.242000            E\n",
      "17648  2014-12-07    280.126000            E\n",
      "17649  2014-12-08    287.208000            E\n",
      "17650  2014-12-09    361.783000            E\n",
      "17651  2014-12-10    383.925000            E\n",
      "17652  2014-12-11    389.403000            E\n",
      "17653  2014-12-12    372.139000            E\n",
      "17654  2014-12-13    631.840000            E\n",
      "17655  2014-12-14   1183.420000            E\n",
      "17656  2014-12-15   1650.920000            E\n",
      "17657  2014-12-16   6151.880000            E\n",
      "17658  2014-12-17   2879.860000            E\n",
      "17659  2014-12-18   1265.160000            E\n",
      "17660  2014-12-19    737.835000            E\n",
      "17661  2014-12-20    520.758000            E\n",
      "17662  2014-12-21    413.107000            E\n",
      "17663  2014-12-22    321.198000            E\n",
      "17664  2014-12-23    413.550000            E\n",
      "17665  2014-12-24   1253.070000            E\n",
      "17666  2014-12-25   1968.820000            E\n",
      "17667  2014-12-26   2305.540000            E\n",
      "17668  2014-12-27   2920.950000            E\n",
      "17669  2014-12-28   4038.590000            E\n",
      "17670  2014-12-29  10443.400000            E\n",
      "17671  2014-12-30  16432.300000            E\n",
      "17672  2014-12-31  23661.900000            E\n",
      "\n",
      "[17673 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Url is used to retrieve daily streamflow data for the gauge_of_interest    \n",
    "url = 'http://www.bom.gov.au/water/hrs/content/data/'+gauge_of_interest+'/'+gauge_of_interest+'_daily_ts.csv'\n",
    "gaugedata = pd.read_csv(url, comment='#')\n",
    "print (gaugedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographic: 134.4197, -14.6953\n",
      "Australian Albers: 263136.9744314623, -1560666.1358515057\n"
     ]
    }
   ],
   "source": [
    "#Url is used to retrieve stream gauge location coordinates. Coordinates are reprojected to Australian Albers   \n",
    "\n",
    "#Search url to find coordinates \n",
    "txt = urllib.request.urlopen(url).read()\n",
    "txt = str(txt)\n",
    "sg_lon = txt.split('\"Location:\", ')[1].split(',\"degrees E\",')[0]\n",
    "sg_lon=float(sg_lon)\n",
    "sg_lat = txt.split(',\"degrees E\", ')[1].split(',\"degrees S\"')[0]\n",
    "sg_lat= \"-\"+sg_lat\n",
    "sg_lat=float(sg_lat)\n",
    "\n",
    "#Reproject to Australian Albers\n",
    "inProj = Proj(init='EPSG:4326')\n",
    "outProj = Proj(init='EPSG:3577')\n",
    "sg_x,sg_y = transform(inProj,outProj,sg_lon,sg_lat)\n",
    "\n",
    "print (\"Geographic: \" + str(sg_lon)+', '+ str(sg_lat))\n",
    "print (\"Australian Albers: \"+ str(sg_x)+', '+str(sg_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Datacube query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Spatiotemporal range and wavelengths/band of interest are defined\n",
    "\n",
    "#Temporal range is defined\n",
    "start_of_epoch = '1987-01-01'\n",
    "end_of_epoch =  '2014-12-31'\n",
    "\n",
    "#Wavelengths/bands of interest are defined\n",
    "bands_of_interest = ['green',\n",
    "                     'red', \n",
    "                     'nir',\n",
    "                     'swir1']\n",
    "\n",
    "#Landsat sensors of interest are defined\n",
    "sensors = ['ls8',\n",
    "    'ls7',\n",
    "    'ls5' ] \n",
    "\n",
    "#Create bounding box around the location of the stream gauge\n",
    "lat_max = sg_lat + 0.05\n",
    "lat_min = sg_lat - 0.05\n",
    "lon_max = sg_lon + 0.05\n",
    "lon_min = sg_lon - 0.05\n",
    "\n",
    "#Create query\n",
    "query = {'time': (start_of_epoch, end_of_epoch)}\n",
    "query['x'] = (lon_min, lon_max)\n",
    "query['y'] = (lat_max, lat_min)\n",
    "query['crs'] = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create cloud mask. This will define which pixel quality (PQ) artefacts are removed from the results.\n",
    "\n",
    "mask_components = {'cloud_acca':'no_cloud',\n",
    "'cloud_shadow_acca' :'no_cloud_shadow',\n",
    "'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "'cloud_fmask' :'no_cloud',\n",
    "'blue_saturated' : False,\n",
    "'green_saturated' : False,\n",
    "'red_saturated' : False,\n",
    "'nir_saturated' : False,\n",
    "'swir1_saturated' : False,\n",
    "'swir2_saturated' : False,\n",
    "'contiguous':True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Datacube extraction\n",
    "The extracted data is first filtered using the criteria in \"mask_components\". The cloudiness of the scenes is then tested, and any scenes that do not meet the given \"cloud_free_threshold\" are discarded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ls8\n",
      "loaded ls7\n",
      "loaded ls5\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "#Retrieve the data for each Landsat sensor\n",
    "\n",
    "sensor_clean = {}\n",
    "cloud_free_threshold = 0.90  ###User modification: set cloud threshold. Default value is \"0.90\" or >90% image and <10% cloud cover\n",
    "                        ###Scenes will be discarded that have less than the cloud threshold worth of image.\n",
    "    \n",
    "for sensor in sensors:\n",
    "    #Load the NBAR and corresponding PQ\n",
    "    sensor_nbar = dc.load(product= sensor+'_nbar_albers', group_by='solar_day', \n",
    "                          measurements = bands_of_interest,  **query)\n",
    "    sensor_pq = dc.load(product= sensor+'_pq_albers', group_by='solar_day', \n",
    "                        fuse_func=ga_pq_fuser, **query)\n",
    "    \n",
    "    #Retrieve the projection information before masking/sorting\n",
    "    crs = sensor_nbar.crs\n",
    "    crswkt = sensor_nbar.crs.wkt\n",
    "    affine = sensor_nbar.affine\n",
    "    \n",
    "    #Ensure there's PQ to go with the NBAR\n",
    "    sensor_nbar = sensor_nbar.sel(time = sensor_pq.time)\n",
    "    \n",
    "    #Apply the PQ masks to the NBAR\n",
    "    quality_mask = masking.make_mask(sensor_pq, **mask_components)\n",
    "    good_data = quality_mask.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "    sensor_nbar2 = sensor_nbar.where(good_data)\n",
    "    \n",
    "    #Calculate the percentage cloud free for each scene\n",
    "    cloud_free = masking.make_mask(sensor_pq, cloud_acca='no_cloud', cloud_fmask='no_cloud', \n",
    "                                   contiguous=True).pixelquality\n",
    "    mostly_cloud_free = cloud_free.mean(dim=('x','y')) >= cloud_free_threshold\n",
    "        \n",
    "    #Discard data that does not meet the cloud_free_threshold\n",
    "    mostly_good = sensor_nbar2.where(mostly_cloud_free).dropna(dim='time', how='all')\n",
    "    mostly_good['product'] = ('time', numpy.repeat(sensor, mostly_good.time.size))    \n",
    "    sensor_clean[sensor] = mostly_good\n",
    "\n",
    "    print('loaded %s' % sensor) \n",
    "    \n",
    "\n",
    "print ('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ls5': <xarray.Dataset>\n",
       " Dimensions:  (time: 246, x: 445, y: 447)\n",
       " Coordinates:\n",
       "   * time     (time) datetime64[ns] 1987-05-25T00:29:06.500000 ...\n",
       "   * y        (y) float64 -1.555e+06 -1.555e+06 -1.555e+06 -1.555e+06 ...\n",
       "   * x        (x) float64 2.576e+05 2.576e+05 2.576e+05 2.577e+05 2.577e+05 ...\n",
       " Data variables:\n",
       "     green    (time, y, x) float64 797.0 750.0 797.0 844.0 797.0 891.0 844.0 ...\n",
       "     red      (time, y, x) float64 880.0 837.0 922.0 964.0 1.006e+03 ...\n",
       "     nir      (time, y, x) float64 2.112e+03 2.164e+03 2.217e+03 2.269e+03 ...\n",
       "     swir1    (time, y, x) float64 2.472e+03 2.472e+03 2.472e+03 2.509e+03 ...\n",
       "     product  (time) <U3 'ls5' 'ls5' 'ls5' 'ls5' 'ls5' 'ls5' 'ls5' 'ls5' ...\n",
       " Attributes:\n",
       "     crs:      EPSG:3577, 'ls7': <xarray.Dataset>\n",
       " Dimensions:  (time: 48, x: 445, y: 447)\n",
       " Coordinates:\n",
       "   * time     (time) datetime64[ns] 1999-07-21T00:57:50 ...\n",
       "   * y        (y) float64 -1.555e+06 -1.555e+06 -1.555e+06 -1.555e+06 ...\n",
       "   * x        (x) float64 2.576e+05 2.576e+05 2.576e+05 2.577e+05 2.577e+05 ...\n",
       " Data variables:\n",
       "     green    (time, y, x) float64 680.0 629.0 655.0 681.0 706.0 757.0 783.0 ...\n",
       "     red      (time, y, x) float64 822.0 822.0 800.0 890.0 958.0 1.003e+03 ...\n",
       "     nir      (time, y, x) float64 1.856e+03 1.823e+03 1.856e+03 1.922e+03 ...\n",
       "     swir1    (time, y, x) float64 2.464e+03 2.345e+03 2.375e+03 2.494e+03 ...\n",
       "     product  (time) <U3 'ls7' 'ls7' 'ls7' 'ls7' 'ls7' 'ls7' 'ls7' 'ls7' ...\n",
       " Attributes:\n",
       "     crs:      EPSG:3577, 'ls8': <xarray.Dataset>\n",
       " Dimensions:  (time: 24, x: 445, y: 447)\n",
       " Coordinates:\n",
       "   * time     (time) datetime64[ns] 2013-04-14T01:06:51.500000 ...\n",
       "   * y        (y) float64 -1.555e+06 -1.555e+06 -1.555e+06 -1.555e+06 ...\n",
       "   * x        (x) float64 2.576e+05 2.576e+05 2.576e+05 2.577e+05 2.577e+05 ...\n",
       " Data variables:\n",
       "     green    (time, y, x) float64 720.0 696.0 719.0 761.0 795.0 775.0 753.0 ...\n",
       "     red      (time, y, x) float64 790.0 739.0 770.0 859.0 922.0 905.0 849.0 ...\n",
       "     nir      (time, y, x) float64 1.842e+03 1.942e+03 1.987e+03 2.035e+03 ...\n",
       "     swir1    (time, y, x) float64 2.192e+03 2.044e+03 2.13e+03 2.309e+03 ...\n",
       "     product  (time) <U3 'ls8' 'ls8' 'ls8' 'ls8' 'ls8' 'ls8' 'ls8' 'ls8' ...\n",
       " Attributes:\n",
       "     crs:      EPSG:3577}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the output\n",
    "sensor_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenate (join) data from different sensors together and sort so that observations are sorted \n",
    "#by time rather than sensor\n",
    "\n",
    "nbar_clean = xr.concat(sensor_clean.values(), dim='time')\n",
    "time_sorted = nbar_clean.time.argsort()\n",
    "nbar_clean = nbar_clean.isel(time=time_sorted)\n",
    "nbar_clean.attrs['crs'] = crs\n",
    "nbar_clean.attrs['affin|e'] = affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 318, x: 445, y: 447)\n",
       "Coordinates:\n",
       "  * y        (y) float64 -1.555e+06 -1.555e+06 -1.555e+06 -1.555e+06 ...\n",
       "  * x        (x) float64 2.576e+05 2.576e+05 2.576e+05 2.577e+05 2.577e+05 ...\n",
       "  * time     (time) datetime64[ns] 1987-05-25T00:29:06.500000 ...\n",
       "Data variables:\n",
       "    green    (time, y, x) float64 797.0 750.0 797.0 844.0 797.0 891.0 844.0 ...\n",
       "    red      (time, y, x) float64 880.0 837.0 922.0 964.0 1.006e+03 ...\n",
       "    nir      (time, y, x) float64 2.112e+03 2.164e+03 2.217e+03 2.269e+03 ...\n",
       "    swir1    (time, y, x) float64 2.472e+03 2.472e+03 2.472e+03 2.509e+03 ...\n",
       "    product  (time) <U3 'ls5' 'ls5' 'ls5' 'ls5' 'ls5' 'ls5' 'ls5' 'ls5' ...\n",
       "Attributes:\n",
       "    crs:      EPSG:3577\n",
       "    affin|e:  | 25.00, 0.00, 257575.00|\\n| 0.00,-25.00,-1555075.00|\\n| 0.00, ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the concatenation worked\n",
    "nbar_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Process stream gauge information\n",
    "Calculate the percentiles of stream flow, and sort the dataframe according to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate \"percentage exceedance\" (perexc) for stream flow values\n",
    "\n",
    "all_data = gaugedata #Import streamflow data from the gauge of interest\n",
    "all_data= all_data.rename(columns={'Flow (ML)':'flow', 'Date':'date'})  #Rename flow and date columns\n",
    "all_data = all_data.sort_values('flow', ascending=[False]) #Sort data by flow value\n",
    "all_data['rank'] = np.arange(len(all_data)) + 1 #Create rank column and values\n",
    "all_data['perexc'] = 100*(all_data['rank'])/(len(all_data)+1) #Calculate probability of each rank\n",
    "all_data= all_data.sort_values(['date']) #Sort data by date\n",
    "all_data=all_data.drop(all_data.columns[[2]], axis=1) #Remove \"Bureau QCode\" column\n",
    "all_data['date']=pd.to_datetime(all_data['date'], format='%Y/%m/%d %H:%M:%S') #Change datetime format\n",
    "all_data.date = all_data.date.map(lambda t: t.strftime('%Y-%m-%d')) #Change datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return just the time and sensor product information from the Datacube extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product_time = nbar_clean[['time', 'product']].to_dataframe() #Add time and product to dataframe\n",
    "product_time.index = product_time.index + pd.Timedelta(hours=10) #Roughly convert to local time\n",
    "product_time.index = product_time.index.map(lambda t: t.strftime('%Y-%m-%d')) #Remove Hours/Minutes Seconds by formatting into a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match the date of stream flow data to the date where satellite information exists¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset_data = pd.merge(all_data, product_time, left_on= 'date', \n",
    "                       right_index=True, how='inner') #Match dates and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset_data['date']=pd.to_datetime(subset_data['date'], format='%Y/%m/%d %H:%M:%S') #Change datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>flow</th>\n",
       "      <th>rank</th>\n",
       "      <th>perexc</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10070</th>\n",
       "      <td>1994-03-09</td>\n",
       "      <td>188518.00000</td>\n",
       "      <td>125</td>\n",
       "      <td>0.707254</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11494</th>\n",
       "      <td>1998-01-31</td>\n",
       "      <td>173314.00000</td>\n",
       "      <td>154</td>\n",
       "      <td>0.871336</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8966</th>\n",
       "      <td>1991-03-01</td>\n",
       "      <td>165236.00000</td>\n",
       "      <td>174</td>\n",
       "      <td>0.984497</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15174</th>\n",
       "      <td>2008-02-28</td>\n",
       "      <td>102069.00000</td>\n",
       "      <td>448</td>\n",
       "      <td>2.534797</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15494</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>93456.40000</td>\n",
       "      <td>511</td>\n",
       "      <td>2.891253</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14838</th>\n",
       "      <td>2007-03-29</td>\n",
       "      <td>65627.30000</td>\n",
       "      <td>749</td>\n",
       "      <td>4.237864</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7862</th>\n",
       "      <td>1988-02-21</td>\n",
       "      <td>50723.70000</td>\n",
       "      <td>923</td>\n",
       "      <td>5.222361</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11926</th>\n",
       "      <td>1999-04-08</td>\n",
       "      <td>44941.30000</td>\n",
       "      <td>1017</td>\n",
       "      <td>5.754215</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13750</th>\n",
       "      <td>2004-04-05</td>\n",
       "      <td>34330.70000</td>\n",
       "      <td>1224</td>\n",
       "      <td>6.925427</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11846</th>\n",
       "      <td>1999-01-18</td>\n",
       "      <td>22067.60000</td>\n",
       "      <td>1613</td>\n",
       "      <td>9.126400</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14790</th>\n",
       "      <td>2007-02-09</td>\n",
       "      <td>20757.30000</td>\n",
       "      <td>1683</td>\n",
       "      <td>9.522462</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13390</th>\n",
       "      <td>2003-04-11</td>\n",
       "      <td>20747.00000</td>\n",
       "      <td>1684</td>\n",
       "      <td>9.528120</td>\n",
       "      <td>ls7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10102</th>\n",
       "      <td>1994-04-10</td>\n",
       "      <td>19563.10000</td>\n",
       "      <td>1733</td>\n",
       "      <td>9.805364</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13766</th>\n",
       "      <td>2004-04-21</td>\n",
       "      <td>15970.80000</td>\n",
       "      <td>1932</td>\n",
       "      <td>10.931312</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12590</th>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>15088.80000</td>\n",
       "      <td>2005</td>\n",
       "      <td>11.344348</td>\n",
       "      <td>ls7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14534</th>\n",
       "      <td>2006-05-29</td>\n",
       "      <td>12350.50000</td>\n",
       "      <td>2215</td>\n",
       "      <td>12.532534</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15862</th>\n",
       "      <td>2010-01-16</td>\n",
       "      <td>11165.10000</td>\n",
       "      <td>2317</td>\n",
       "      <td>13.109653</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15558</th>\n",
       "      <td>2009-03-18</td>\n",
       "      <td>9148.70000</td>\n",
       "      <td>2552</td>\n",
       "      <td>14.439289</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15958</th>\n",
       "      <td>2010-04-22</td>\n",
       "      <td>9130.44000</td>\n",
       "      <td>2555</td>\n",
       "      <td>14.456263</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14550</th>\n",
       "      <td>2006-06-14</td>\n",
       "      <td>7964.85000</td>\n",
       "      <td>2744</td>\n",
       "      <td>15.525631</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13326</th>\n",
       "      <td>2003-02-06</td>\n",
       "      <td>7578.34000</td>\n",
       "      <td>2813</td>\n",
       "      <td>15.916035</td>\n",
       "      <td>ls7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13422</th>\n",
       "      <td>2003-05-13</td>\n",
       "      <td>7561.84000</td>\n",
       "      <td>2815</td>\n",
       "      <td>15.927351</td>\n",
       "      <td>ls7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12238</th>\n",
       "      <td>2000-02-14</td>\n",
       "      <td>7458.34000</td>\n",
       "      <td>2837</td>\n",
       "      <td>16.051828</td>\n",
       "      <td>ls7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8294</th>\n",
       "      <td>1989-04-28</td>\n",
       "      <td>6861.32000</td>\n",
       "      <td>2937</td>\n",
       "      <td>16.617630</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17046</th>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>6770.11000</td>\n",
       "      <td>2948</td>\n",
       "      <td>16.679869</td>\n",
       "      <td>ls8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13798</th>\n",
       "      <td>2004-05-23</td>\n",
       "      <td>6583.97000</td>\n",
       "      <td>2989</td>\n",
       "      <td>16.911848</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11782</th>\n",
       "      <td>1998-11-15</td>\n",
       "      <td>6445.35000</td>\n",
       "      <td>3017</td>\n",
       "      <td>17.070273</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10774</th>\n",
       "      <td>1996-02-11</td>\n",
       "      <td>5965.80000</td>\n",
       "      <td>3119</td>\n",
       "      <td>17.647392</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8214</th>\n",
       "      <td>1989-02-07</td>\n",
       "      <td>5670.17000</td>\n",
       "      <td>3184</td>\n",
       "      <td>18.015164</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14566</th>\n",
       "      <td>2006-06-30</td>\n",
       "      <td>5666.95000</td>\n",
       "      <td>3187</td>\n",
       "      <td>18.032138</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8422</th>\n",
       "      <td>1989-09-03</td>\n",
       "      <td>67.26640</td>\n",
       "      <td>15882</td>\n",
       "      <td>89.860812</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9078</th>\n",
       "      <td>1991-06-21</td>\n",
       "      <td>67.22290</td>\n",
       "      <td>15885</td>\n",
       "      <td>89.877787</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9158</th>\n",
       "      <td>1991-09-09</td>\n",
       "      <td>66.84900</td>\n",
       "      <td>15907</td>\n",
       "      <td>90.002263</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8022</th>\n",
       "      <td>1988-07-30</td>\n",
       "      <td>66.18820</td>\n",
       "      <td>15946</td>\n",
       "      <td>90.222926</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510</th>\n",
       "      <td>1992-08-26</td>\n",
       "      <td>65.56650</td>\n",
       "      <td>15971</td>\n",
       "      <td>90.364377</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7990</th>\n",
       "      <td>1988-06-28</td>\n",
       "      <td>65.21860</td>\n",
       "      <td>15988</td>\n",
       "      <td>90.460564</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7750</th>\n",
       "      <td>1987-11-01</td>\n",
       "      <td>63.01440</td>\n",
       "      <td>16107</td>\n",
       "      <td>91.133869</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10262</th>\n",
       "      <td>1994-09-17</td>\n",
       "      <td>61.03190</td>\n",
       "      <td>16178</td>\n",
       "      <td>91.535589</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10646</th>\n",
       "      <td>1995-10-06</td>\n",
       "      <td>58.65370</td>\n",
       "      <td>16257</td>\n",
       "      <td>91.982573</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8038</th>\n",
       "      <td>1988-08-15</td>\n",
       "      <td>58.01030</td>\n",
       "      <td>16285</td>\n",
       "      <td>92.140998</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9174</th>\n",
       "      <td>1991-09-25</td>\n",
       "      <td>57.22770</td>\n",
       "      <td>16316</td>\n",
       "      <td>92.316397</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8438</th>\n",
       "      <td>1989-09-19</td>\n",
       "      <td>55.58870</td>\n",
       "      <td>16373</td>\n",
       "      <td>92.638905</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10278</th>\n",
       "      <td>1994-10-03</td>\n",
       "      <td>55.26260</td>\n",
       "      <td>16385</td>\n",
       "      <td>92.706801</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8790</th>\n",
       "      <td>1990-09-06</td>\n",
       "      <td>54.00610</td>\n",
       "      <td>16421</td>\n",
       "      <td>92.910490</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9542</th>\n",
       "      <td>1992-09-27</td>\n",
       "      <td>53.51490</td>\n",
       "      <td>16430</td>\n",
       "      <td>92.961412</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8454</th>\n",
       "      <td>1989-10-05</td>\n",
       "      <td>49.78460</td>\n",
       "      <td>16522</td>\n",
       "      <td>93.481951</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9190</th>\n",
       "      <td>1991-10-11</td>\n",
       "      <td>49.60630</td>\n",
       "      <td>16533</td>\n",
       "      <td>93.544189</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8502</th>\n",
       "      <td>1989-11-22</td>\n",
       "      <td>45.14570</td>\n",
       "      <td>16660</td>\n",
       "      <td>94.262759</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606</th>\n",
       "      <td>1992-11-30</td>\n",
       "      <td>44.39790</td>\n",
       "      <td>16688</td>\n",
       "      <td>94.421184</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9206</th>\n",
       "      <td>1991-10-27</td>\n",
       "      <td>40.69110</td>\n",
       "      <td>16802</td>\n",
       "      <td>95.066199</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9574</th>\n",
       "      <td>1992-10-29</td>\n",
       "      <td>40.35420</td>\n",
       "      <td>16810</td>\n",
       "      <td>95.111463</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11062</th>\n",
       "      <td>1996-11-25</td>\n",
       "      <td>40.14810</td>\n",
       "      <td>16818</td>\n",
       "      <td>95.156727</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9222</th>\n",
       "      <td>1991-11-12</td>\n",
       "      <td>39.75290</td>\n",
       "      <td>16837</td>\n",
       "      <td>95.264230</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8086</th>\n",
       "      <td>1988-10-02</td>\n",
       "      <td>36.86390</td>\n",
       "      <td>16913</td>\n",
       "      <td>95.694240</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8486</th>\n",
       "      <td>1989-11-06</td>\n",
       "      <td>35.47090</td>\n",
       "      <td>16940</td>\n",
       "      <td>95.847007</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8102</th>\n",
       "      <td>1988-10-18</td>\n",
       "      <td>29.37300</td>\n",
       "      <td>17065</td>\n",
       "      <td>96.554260</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8838</th>\n",
       "      <td>1990-10-24</td>\n",
       "      <td>24.94010</td>\n",
       "      <td>17174</td>\n",
       "      <td>97.170986</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8854</th>\n",
       "      <td>1990-11-09</td>\n",
       "      <td>15.83010</td>\n",
       "      <td>17382</td>\n",
       "      <td>98.347856</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17606</th>\n",
       "      <td>2014-10-26</td>\n",
       "      <td>13.51980</td>\n",
       "      <td>17419</td>\n",
       "      <td>98.557203</td>\n",
       "      <td>ls8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>1993-12-03</td>\n",
       "      <td>9.90214</td>\n",
       "      <td>17467</td>\n",
       "      <td>98.828788</td>\n",
       "      <td>ls5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date          flow   rank     perexc product\n",
       "10070 1994-03-09  188518.00000    125   0.707254     ls5\n",
       "11494 1998-01-31  173314.00000    154   0.871336     ls5\n",
       "8966  1991-03-01  165236.00000    174   0.984497     ls5\n",
       "15174 2008-02-28  102069.00000    448   2.534797     ls5\n",
       "15494 2009-01-13   93456.40000    511   2.891253     ls5\n",
       "14838 2007-03-29   65627.30000    749   4.237864     ls5\n",
       "7862  1988-02-21   50723.70000    923   5.222361     ls5\n",
       "11926 1999-04-08   44941.30000   1017   5.754215     ls5\n",
       "13750 2004-04-05   34330.70000   1224   6.925427     ls5\n",
       "11846 1999-01-18   22067.60000   1613   9.126400     ls5\n",
       "14790 2007-02-09   20757.30000   1683   9.522462     ls5\n",
       "13390 2003-04-11   20747.00000   1684   9.528120     ls7\n",
       "10102 1994-04-10   19563.10000   1733   9.805364     ls5\n",
       "13766 2004-04-21   15970.80000   1932  10.931312     ls5\n",
       "12590 2001-01-31   15088.80000   2005  11.344348     ls7\n",
       "14534 2006-05-29   12350.50000   2215  12.532534     ls5\n",
       "15862 2010-01-16   11165.10000   2317  13.109653     ls5\n",
       "15558 2009-03-18    9148.70000   2552  14.439289     ls5\n",
       "15958 2010-04-22    9130.44000   2555  14.456263     ls5\n",
       "14550 2006-06-14    7964.85000   2744  15.525631     ls5\n",
       "13326 2003-02-06    7578.34000   2813  15.916035     ls7\n",
       "13422 2003-05-13    7561.84000   2815  15.927351     ls7\n",
       "12238 2000-02-14    7458.34000   2837  16.051828     ls7\n",
       "8294  1989-04-28    6861.32000   2937  16.617630     ls5\n",
       "17046 2013-04-14    6770.11000   2948  16.679869     ls8\n",
       "13798 2004-05-23    6583.97000   2989  16.911848     ls5\n",
       "11782 1998-11-15    6445.35000   3017  17.070273     ls5\n",
       "10774 1996-02-11    5965.80000   3119  17.647392     ls5\n",
       "8214  1989-02-07    5670.17000   3184  18.015164     ls5\n",
       "14566 2006-06-30    5666.95000   3187  18.032138     ls5\n",
       "...          ...           ...    ...        ...     ...\n",
       "8422  1989-09-03      67.26640  15882  89.860812     ls5\n",
       "9078  1991-06-21      67.22290  15885  89.877787     ls5\n",
       "9158  1991-09-09      66.84900  15907  90.002263     ls5\n",
       "8022  1988-07-30      66.18820  15946  90.222926     ls5\n",
       "9510  1992-08-26      65.56650  15971  90.364377     ls5\n",
       "7990  1988-06-28      65.21860  15988  90.460564     ls5\n",
       "7750  1987-11-01      63.01440  16107  91.133869     ls5\n",
       "10262 1994-09-17      61.03190  16178  91.535589     ls5\n",
       "10646 1995-10-06      58.65370  16257  91.982573     ls5\n",
       "8038  1988-08-15      58.01030  16285  92.140998     ls5\n",
       "9174  1991-09-25      57.22770  16316  92.316397     ls5\n",
       "8438  1989-09-19      55.58870  16373  92.638905     ls5\n",
       "10278 1994-10-03      55.26260  16385  92.706801     ls5\n",
       "8790  1990-09-06      54.00610  16421  92.910490     ls5\n",
       "9542  1992-09-27      53.51490  16430  92.961412     ls5\n",
       "8454  1989-10-05      49.78460  16522  93.481951     ls5\n",
       "9190  1991-10-11      49.60630  16533  93.544189     ls5\n",
       "8502  1989-11-22      45.14570  16660  94.262759     ls5\n",
       "9606  1992-11-30      44.39790  16688  94.421184     ls5\n",
       "9206  1991-10-27      40.69110  16802  95.066199     ls5\n",
       "9574  1992-10-29      40.35420  16810  95.111463     ls5\n",
       "11062 1996-11-25      40.14810  16818  95.156727     ls5\n",
       "9222  1991-11-12      39.75290  16837  95.264230     ls5\n",
       "8086  1988-10-02      36.86390  16913  95.694240     ls5\n",
       "8486  1989-11-06      35.47090  16940  95.847007     ls5\n",
       "8102  1988-10-18      29.37300  17065  96.554260     ls5\n",
       "8838  1990-10-24      24.94010  17174  97.170986     ls5\n",
       "8854  1990-11-09      15.83010  17382  98.347856     ls5\n",
       "17606 2014-10-26      13.51980  17419  98.557203     ls8\n",
       "9974  1993-12-03       9.90214  17467  98.828788     ls5\n",
       "\n",
       "[318 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=subset_data.sort_values('perexc')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create flow duration curve (FDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prepare flow and percentage exceedance variables for plotting on FDC\n",
    "\n",
    "#Preapre all data\n",
    "sorted_a_flow=sorted(all_data.flow, reverse=True)\n",
    "sorted_a_pe=sorted(all_data.perexc)\n",
    "\n",
    "#Prepare the matched subset data\n",
    "sorted_s_flow=sorted(subset_data.flow, reverse=True)\n",
    "sorted_s_pe=sorted(subset_data.perexc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creation of FDC plot. Please note that this graph is not interactive\n",
    "\n",
    "#Plot details\n",
    "fig = plt.figure(figsize=(10,10)) #Edit size of plot ##User should format as required\n",
    "plt.title('Interactive flow duration curve: '+gauge_of_interest, size=14) #Plot title ##User should format if required\n",
    "plt.grid(True) #Add gridlines to the figure\n",
    "pyplot.yscale('log') #set up Y axis as a log scale\n",
    "plt.subplots_adjust(left=0.10, right=0.96, top=0.95, bottom=0.12) #Set border dimensions  ##User should format if required\n",
    "fig.patch.set_facecolor('white')  #Make border white ##User should format if required\n",
    "fig.patch.set_alpha(0.99)  #Make border white ##User should format if required\n",
    "\n",
    "#create plot of percent exceedance\n",
    "plt.plot(sorted_a_pe,sorted_a_flow,'o',label= 'All discharge values')  #plot all discharge values ##User should format series if required\n",
    "plt.plot(sorted_s_pe,sorted_s_flow,'ro',label='Discharge values with suitable satellite imagery') #plot matched discharge values ##User should format series if required\n",
    "\n",
    "#axis and legend details\n",
    "plt.axis([-5, 105, 0.0001, 1000000])  ###User modification: set axis discharge values appropriate for streamflow range\n",
    "plt.xticks(rotation=45,size=14) #Rotate and format size of date labels ##User should format if required\n",
    "plt.yticks(size=14) #Rotate and format size of date labels ##User should format if required\n",
    "plt.ylabel('Discharge (m$^3$ day$^{-1}$)', size=14) #Set Y label\n",
    "plt.xlabel('Percentage of time equalled or exceeded (%)', size=14) #Set X label\n",
    "plt.legend(edgecolor ='none', ncol=2, loc=9, fontsize=12) #Set legend location on plot ##User should format if required\n",
    "\n",
    "plt.show() #Show plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Save figure\n",
    "# ###User modification: edit directory to save figure\n",
    "# %cd /g/data/r78/ext547/Output/FDC/ \n",
    "# plt.savefig('FDC_'+gauge_of_interest+'.jpg') ##User should format file name if required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of WOfS imagery\n",
    "Set the flow percentile range of interest, create the Datacube query and create the WOfS image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the percentage exceedance range of interest. The WOfS image will only include scenes from within this flow range\n",
    "###User modification: set flow percentage exceedance range of interest between 0 to 100%\n",
    "wofs_range_min = 0 #minimum value to include\n",
    "wofs_range_max = 100 #maximum value to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Datacube query for WOfS event of interest\n",
    "\n",
    "#EITHER... Create a large bounding box around the location of the stream gauge\n",
    "###User modification: change area of interest to suit gauge location in relation to satellite pass\n",
    "# lat_max = sg_lat + 0.5\n",
    "# lat_min = sg_lat - 0.5\n",
    "# lon_max = sg_lon + 0.7\n",
    "# lon_min = sg_lon - 0.4\n",
    "\n",
    "#...OR... create smaller bounding box around the location of the stream gauge\n",
    "###User modification: change area of interest to suit gauge location in relation to satellite pass\n",
    "lat_max = sg_lat + 0.05\n",
    "lat_min = sg_lat - 0.05\n",
    "lon_max = sg_lon + 0.05\n",
    "lon_min = sg_lon - 0.05\n",
    "\n",
    "#Create query\n",
    "query['x'] = (lon_min, lon_max)\n",
    "query['y'] = (lat_max, lat_min)\n",
    "query['crs'] = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Search for scenes that fit within specified percentage exceedance range\n",
    "subset_data['date']=pd.to_datetime(subset_data['date'], format='%Y/%m/%d %H:%M:%S') #Change datetime format\n",
    "FDC_subset=subset_data[subset_data['perexc'].between(wofs_range_min, wofs_range_max, inclusive=True)] #Return percentage exceedance range of interest\n",
    "FDC_subset_count=len(FDC_subset.index) #Define the number of scenes within this range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a query to store spatiotemporal information from the previous landsat query\n",
    "wofs_query = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Retrieve wofs data array for each date specified within the FDC range of interest and save to multiple arrays\n",
    "\n",
    "wofs_subset = {}\n",
    "for i in range(len(FDC_subset)):\n",
    "    wofs_query['time'] = (FDC_subset.date.iloc[i]+ datetime.timedelta(days=-2)), (FDC_subset.date.iloc[i]+ datetime.timedelta(days=+2))\n",
    "    wofs_data = dcwofs.load(product = 'old_wofs', **wofs_query)\n",
    "    wofs_subset[i]=wofs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenate (join) the data from the different WOfS scenes together and sort so that observations are sorted \n",
    "#by time\n",
    "\n",
    "xr_wofs = xr.DataArray(wofs_subset)\n",
    "list(wofs_subset.values())\n",
    "wofs_subset2 = {k: x for (k, x) in wofs_subset.items() if x}\n",
    "wofs_subset3=xr.concat(wofs_subset2.values(),dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove all values that are not defined as \"wet water\" (value of 128)\n",
    "wofs128=wofs_subset3\n",
    "wofs128['water']=wofs_subset3.water.where(wofs_subset3.water==128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add water values for each pixel and turn into a percentage\n",
    "\n",
    "#Add the water value for each pixel in the array over time\n",
    "wofs128_v2 = wofs128.sum(dim = 'time')\n",
    "\n",
    "#Take the average of water value at each pixel and turn into a percentage\n",
    "wofs128_v2 = wofs128_v2/ 128\n",
    "wofs128_v2 = wofs128_v2 / FDC_subset_count\n",
    "wofs128_v2 = wofs128_v2*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up the WOfS colour ramp and corresponding thresholds\n",
    "wofs_cmap = mpl.colors.ListedColormap(['#C8B97D','#B3E5FC','#81D4FA','#4FC3F7','#29B6F6','#039BE5',\n",
    "                                       '#0288D1','#0277BD', '#01579B','#1A237E','#02033a','#5e0799'])##User should format as required\n",
    "wofs_bounds = [0.1,0.1,5,10,20,30,40,50,60,70,80,90,100] ##User should format as required\n",
    "wofs_norm = mpl.colors.BoundaryNorm(wofs_bounds, wofs_cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create a WOfS image for the specified percentage exceedance range of interest. \n",
    "#The image shows the percentage of time each pixel contains water during the specified range of interest\n",
    "\n",
    "#Create widget that enables interaction with plot.\n",
    "w = widgets.HTML(\"Event information appears here when you click on the figure\")\n",
    "def callback(event):\n",
    "    global x, y\n",
    "    x, y = int(event.xdata + 0.5), int(event.ydata + 0.5)\n",
    "    w.value = 'X: {}, Y: {}'.format(x,y) \n",
    "fig.canvas.mpl_connect('button_press_event', callback)\n",
    "\n",
    "#Create image\n",
    "fig = plt.figure(figsize =(12,8)) #Set figure size ##User should format if required\n",
    "i= wofs128_v2.water.plot.imshow(cmap = wofs_cmap,norm=wofs_norm,vmin = 0, vmax = 100)#create WOfS image\n",
    "\n",
    "#Format image\n",
    "fig.delaxes(fig.axes[1]) #Remove pre-defined colour bar\n",
    "fig.colorbar(i, ticks=wofs_bounds, spacing='proportional', \n",
    "             extend='min').set_label(label='Water (WOfS) present during clear observations(%)',\n",
    "             size=12) #Add definable colour bar\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05) #Set border size\n",
    "fig.patch.set_facecolor('white') #Ensure border is white\n",
    "fig.patch.set_alpha(0.99) #Ensure border is white\n",
    "plt.axis('off') #Remove axis\n",
    "\n",
    "plt.show() #Create image\n",
    "display(w) #Create image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #save figure\n",
    "# ###User modification: edit directory to save figure\n",
    "# %cd /g/data/r78/ext547/Output/wofs/FDC/\n",
    "# plt.savefig('FDC_WOfS_0-5_small.jpg') ##User should format file name if required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examination of overbank flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Take the sum of water present at each pixel over the specified flow percentile range\n",
    "wofs_area_ar = wofs128.sum(dim = ['longitude','latitude']) #sum pixels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#process data to allow the merge of streamflow data with WOfS data\n",
    "wofs_area_py = wofs_area_ar.to_dataframe() #Convert wofs array into a pandas dataframe\n",
    "wofs_area_py.index = wofs_area_py.index + pd.Timedelta(hours=10) #Roughly convert to time to local time\n",
    "wofs_area_py.index = wofs_area_py.index.map(lambda t: t.strftime('%Y-%m-%d')) #Remove Hours/Minutes Seconds by formatting into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reformat date of streamflow data prior to merge\n",
    "subset_data.date = subset_data.date.map(lambda t: t.strftime('%Y-%m-%d')) #Change datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge streamflow and WOfS dataframe\n",
    "wofs_area = pd.merge(subset_data, wofs_area_py, left_on= 'date', right_index=True, how='inner') #merge\n",
    "wofs_area=wofs_area[~wofs_area.index.duplicated(keep='last')]  #drop duplicates from WOfS dataframe (duplicates occur because of how WOfS data was loaded (searching days either side of the satellite pass))\n",
    "wofs_area = wofs_area.sort_values('perexc', ascending=[True]) #Sort data by percentage exceedance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Creation of plot that shows the amount of water pixels for each percentage discharge value\n",
    "\n",
    "#Plot details\n",
    "fig = plt.figure(figsize=(10,8)) #Edit size of plot ##User should format as required\n",
    "plt.title(gauge_of_interest, size=12) #Plot title ##User should format if required\n",
    "plt.grid(True) #Add gridlines to the figure\n",
    "plt.subplots_adjust(left=0.18, right=0.96, top=0.95, bottom=0.12) #Set border dimensions  ##User should format if required\n",
    "fig.patch.set_facecolor('white')  #Ensure border white ##User should format if required\n",
    "fig.patch.set_alpha(0.99)  #Ensure border white ##User should format if required\n",
    "\n",
    "#Create plot\n",
    "plt.plot(wofs_area.perexc, wofs_area.water, 'ro')  #Plot percentage exceedance vs. number of pixels  ##User should format series if required\n",
    "\n",
    "#Axis and legend details\n",
    "plt.xticks(size=12) #Format size of date labels ##User should format if required\n",
    "plt.yticks(size=12) #Format size of date labels ##User should format if required\n",
    "plt.ylabel('Number of pixels that contain water', size=12) #Set Y label\n",
    "plt.xlabel('Percentage of time equalled or exceeded (%)', size=12) #Set X label\n",
    "\n",
    "plt.show() #Show plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Save figure\n",
    "# ###User modification: edit directory to save figure\n",
    "# %cd /g/data/r78/ext547/Output/wofs/overbank\n",
    "# plt.savefig(gauge_of_interest+'.jpg') #User should format file name, if required"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "widgets": {
   "state": {
    "6dc82a33fe67407293537fd5b961062a": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
