{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bore information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example notebook describes how to retrieve data for a small region and epoch of interest, concatenate data from available sensors and calculate the annual mean NDVI values.  You can then select a location of interest based on the change between years, retrieve an NDVI time series for that location and select imagery from before and after the change event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "%pylab notebook\n",
    "import datacube\n",
    "from datacube.storage import masking\n",
    "from datacube.storage.masking import mask_to_dict\n",
    "from datacube.storage.storage import write_dataset_to_netcdf\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import rasterio\n",
    "import urllib\n",
    "from pyproj import Proj, transform\n",
    "from dateutil import tz\n",
    "from_zone = tz.tzutc()\n",
    "to_zone = tz.tzlocal()\n",
    "dc = datacube.Datacube(app='dc-show changes in annual mean NDVI values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-09T11:09:06.502514",
     "start_time": "2016-06-09T11:09:04.805211"
    }
   },
   "outputs": [],
   "source": [
    "# %pylab notebook\n",
    "# import datacube\n",
    "# import xarray as xr\n",
    "# from datacube.storage import masking\n",
    "# from datacube.storage.masking import mask_to_dict\n",
    "# from matplotlib.backends.backend_pdf import PdfPages\n",
    "# from matplotlib import pyplot as plt\n",
    "# import matplotlib.dates\n",
    "# from IPython.display import display\n",
    "# import ipywidgets as widgets\n",
    "# import datetime\n",
    "# import rasterio\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from pyproj import Proj, transform\n",
    "# from datacube.storage.storage import write_dataset_to_netcdf\n",
    "# from dateutil import tz\n",
    "# import csv\n",
    "# import rasterio\n",
    "# from_zone = tz.tzutc()\n",
    "# to_zone = tz.tzlocal()\n",
    "# from datacube.storage.storage import write_dataset_to_netcdf\n",
    "# dc = datacube.Datacube(app='dc-show changes in annual mean NDVI values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import borehole water level and location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert the ID code for the borehole of interest\n",
    "\n",
    "bore_of_interest= 'RN010167'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read bore data. Please note the borehole data will need to be downloaded from the BoM groundwater explorer  \n",
    "#and saved to your work space on the NCI\n",
    "\n",
    "#import water level information from csv\n",
    "all_data= pd.read_csv('/g/data/r78/Geohack/Input/4_bore/'+bore_of_interest+'.csv') ### User requirement, change directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDA 1994: 134.061 -19.803\n",
      "Australian Albers: 215034.25619941473 -2123928.8430569237\n"
     ]
    }
   ],
   "source": [
    "#Import or enter borehole coordinates\n",
    "\n",
    "#Either...\n",
    "#Enter coordinates in GDA94 as decimal degree format\n",
    "# long= 134.061\n",
    "# lat=-19.803\n",
    "\n",
    "#Or...\n",
    "#Read coordinates from a csv saved in your work space ### User requirement: hash out if entered coordinates above\n",
    "coordinates_of_interest= pd.read_csv('/g/data/r78/Geohack/Input/4_bore/Bore_Detailed.csv')\n",
    "coordinates_of_interest=coordinates_of_interest.set_index('Bore ID').loc[bore_of_interest] #read csv\n",
    "bh_long=coordinates_of_interest.Longitude #return long\n",
    "bh_lat=coordinates_of_interest.Latitude #return lat\n",
    "\n",
    "#reproject\n",
    "inProj = Proj(init='EPSG:4326')\n",
    "outProj = Proj(init='EPSG:3577')\n",
    "bh_x,bh_y = transform(inProj,outProj,bh_long,bh_lat)\n",
    "\n",
    "print (\"GDA 1994:\",bh_long,bh_lat)\n",
    "print (\"Australian Albers:\", bh_x,bh_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Datacube query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatiotemporal range and wavelengths/band of interest are defined\n",
    "\n",
    "#Define temporal range\n",
    "start_of_epoch = '1987-01-01'\n",
    "end_of_epoch =  '2014-12-31'\n",
    "\n",
    "#Define wavelengths/bands of interest\n",
    "bands_of_interest = ['green',\n",
    "                     'red', \n",
    "                     'nir',\n",
    "                     'swir1']\n",
    "\n",
    "#Define sensors of interest\n",
    "sensors = ['ls8',\n",
    "    'ls7',\n",
    "    'ls5' ] \n",
    "\n",
    "#Create bounding box around the location of the stream gauge\n",
    "lat_max = bh_lat + 0.05\n",
    "lat_min = bh_lat - 0.05\n",
    "lon_max = bh_long + 0.05\n",
    "lon_min = bh_long - 0.05\n",
    "\n",
    "#Create query\n",
    "query = {'time': (start_of_epoch, end_of_epoch)}\n",
    "query['x'] = (lon_min, lon_max)\n",
    "query['y'] = (lat_max, lat_min)\n",
    "query['crs'] = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': ('1987-01-01', '2014-12-31'), 'x': (134.011, 134.11100000000002), 'y': (-19.753, -19.853000000000002), 'crs': 'EPSG:4326'}\n"
     ]
    }
   ],
   "source": [
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create cloud mask. This will define which pixel quality (PQ) artefacts are removed from the results.\n",
    "\n",
    "mask_components = {'cloud_acca':'no_cloud',\n",
    "'cloud_shadow_acca' :'no_cloud_shadow',\n",
    "'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "'cloud_fmask' :'no_cloud',\n",
    "'blue_saturated' : False,\n",
    "'green_saturated' : False,\n",
    "'red_saturated' : False,\n",
    "'nir_saturated' : False,\n",
    "'swir1_saturated' : False,\n",
    "'swir2_saturated' : False,\n",
    "'contiguous':True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Datacube extraction\n",
    "The extracted data is first filtered using the criteria in \"mask_components\". The cloudiness of the scenes is then tested, and any scenes that do not meet the given \"cloud_threshold\" are discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ls8\n",
      "loaded ls7\n",
      "loaded ls5\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "#Retrieve the data for each Landsat sensor\n",
    "\n",
    "sensor_clean = {}\n",
    "cloud_threshold = 0.90  ###User requirement: set cloud threshold. Default value is \"0.90\" or >90% image and <10% cloud cover\n",
    "                        ###Scenes will not be retrieved that have less than the cloud threshold worth of image.\n",
    "\n",
    "for sensor in sensors:\n",
    "    #Load the NBAR and corresponding PQ\n",
    "    sensor_nbar = dc.load(product= sensor+'_nbar_albers', group_by='solar_day', \n",
    "                          measurements = bands_of_interest,  **query)\n",
    "    sensor_pq = dc.load(product= sensor+'_pq_albers', group_by='solar_day', \n",
    "                        fuse_func=ga_pq_fuser, **query)\n",
    "    \n",
    "    #Retrieve the projection information before masking/sorting\n",
    "    crs = sensor_nbar.crs\n",
    "    crswkt = sensor_nbar.crs.wkt\n",
    "    affine = sensor_nbar.affine\n",
    "    \n",
    "    #Ensure there's PQ to go with the NBAR\n",
    "    sensor_nbar = sensor_nbar.sel(time = sensor_pq.time)\n",
    "    \n",
    "    #Apply the PQ masks to the NBAR\n",
    "    quality_mask = masking.make_mask(sensor_pq, **mask_components)\n",
    "    good_data = quality_mask.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "    sensor_nbar2 = sensor_nbar.where(good_data)\n",
    "    \n",
    "    #Calculate the percentage cloud free for each scene\n",
    "    cloud_free = masking.make_mask(sensor_pq, cloud_acca='no_cloud', cloud_fmask='no_cloud', \n",
    "                                   contiguous=True).pixelquality\n",
    "    mostly_cloud_free = cloud_free.mean(dim=('x','y')) >= cloud_threshold\n",
    "        \n",
    "    #Discard data that does not meet the cloud_threshold\n",
    "    mostly_good = sensor_nbar2.where(mostly_cloud_free).dropna(dim='time', how='all')\n",
    "    mostly_good['product'] = ('time', numpy.repeat(sensor, mostly_good.time.size))    \n",
    "    sensor_clean[sensor] = mostly_good\n",
    "\n",
    "    print('loaded %s' % sensor) \n",
    "    \n",
    "\n",
    "print ('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Group PQ by solar day to avoid idiosyncracies of N/S overlap differences in PQ algorithm performance\n",
    "# pq_albers_product = dc.index.products.get_by_name(sensors[0]+'_pq_albers')\n",
    "# valid_bit = pq_albers_product.measurements['pixelquality']['flags_definition']['contiguous']['bits']\n",
    "\n",
    "# def pq_fuser(dest, src):\n",
    "#     valid_val = (1 << valid_bit)\n",
    "\n",
    "#     no_data_dest_mask = ~(dest & valid_val).astype(bool)\n",
    "#     np.copyto(dest, src, where=no_data_dest_mask)\n",
    "\n",
    "#     both_data_mask = (valid_val & dest & src).astype(bool)\n",
    "#     np.copyto(dest, src & dest, where=both_data_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define which pixel quality artefacts you want removed from the results\n",
    "# mask_components = {'cloud_acca':'no_cloud',\n",
    "# 'cloud_shadow_acca' :'no_cloud_shadow',\n",
    "# 'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "# 'cloud_fmask' :'no_cloud',\n",
    "# 'blue_saturated' : False,\n",
    "# 'green_saturated' : False,\n",
    "# 'red_saturated' : False,\n",
    "# 'nir_saturated' : False,\n",
    "# 'swir1_saturated' : False,\n",
    "# 'swir2_saturated' : False,\n",
    "# 'contiguous':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Retrieve the NBAR and PQ data for sensor n\n",
    "# sensor_clean = {}\n",
    "# for sensor in sensors:\n",
    "#     #Load the NBAR and corresponding PQ\n",
    "#     sensor_nbar = dc.load(product= sensor+'_nbar_albers', group_by='solar_day', measurements = bands_of_interest,  **query)\n",
    "#     sensor_pq = dc.load(product= sensor+'_pq_albers', group_by='solar_day', fuse_func=pq_fuser, **query)\n",
    "#     #grab the projection info before masking/sorting\n",
    "#     crs = sensor_nbar.crs\n",
    "#     crswkt = sensor_nbar.crs.wkt\n",
    "#     affine = sensor_nbar.affine\n",
    "#     #This line is to make sure there's PQ to go with the NBAR\n",
    "#     sensor_nbar = sensor_nbar.sel(time = sensor_pq.time)\n",
    "#     #Apply the PQ masks to the NBAR\n",
    "#     cloud_free = masking.make_mask(sensor_pq, **mask_components)\n",
    "#     good_data = cloud_free.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "#     sensor_nbar = sensor_nbar.where(good_data)\n",
    "#     sensor_clean[sensor] = sensor_nbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 567, x: 425, y: 452)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1987-05-25T00:30:42.500000 ...\n",
       "  * y        (y) float64 -2.118e+06 -2.118e+06 -2.118e+06 -2.118e+06 ...\n",
       "  * x        (x) float64 2.097e+05 2.098e+05 2.098e+05 2.098e+05 2.098e+05 ...\n",
       "Data variables:\n",
       "    green    (time, y, x) int16 1057 1006 1057 1108 1057 1057 1108 1160 1160 ...\n",
       "    red      (time, y, x) int16 1958 2004 2004 1958 1958 1912 1912 1819 1819 ...\n",
       "    nir      (time, y, x) int16 2698 2754 2809 2809 2864 2754 2698 2698 2643 ...\n",
       "    swir1    (time, y, x) int16 4116 4116 4116 3997 3957 3997 3957 3679 3719 ...\n",
       "Attributes:\n",
       "    crs:      EPSG:3577"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the output\n",
    "sensor_nbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate data from different sensors together and sort so that observations are sorted by time rather\n",
    "# than sensor\n",
    "nbar_clean = xr.concat(sensor_clean.values(), dim='time')\n",
    "time_sorted = nbar_clean.time.argsort()\n",
    "nbar_clean = nbar_clean.isel(time=time_sorted)\n",
    "nbar_clean.attrs['crs'] = crs\n",
    "nbar_clean.attrs['affin|e'] = affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Process borehole water level information\n",
    "Calculate the percentiles of water level height, and sort the dataframe according to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bore ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Variable</th>\n",
       "      <th>Result (m)</th>\n",
       "      <th>Quality Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-04-12 01:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.98</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-04-19 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.98</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-04-26</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.98</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-05-03</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.97</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-05-10 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.97</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-05-17 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.96</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-05-24 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.97</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-06-28 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.97</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-07-05 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.98</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-07-17 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>11.00</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-07-19 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>11.00</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-07-26 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.99</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-08-02</td>\n",
       "      <td>SWL</td>\n",
       "      <td>11.00</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-08-09 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>11.00</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-08-16 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>11.00</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-09-27 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>11.00</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-10-04</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.97</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-10-11 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.97</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-10-18 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.95</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-11-15 01:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.95</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1972-11-22 01:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.93</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1973-01-10 01:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.93</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1973-01-17 01:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.92</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1973-01-24 01:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.92</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1973-01-31 01:00</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.92</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1973-02-07 01:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.93</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1973-02-14 01:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.92</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1973-02-21 01:00</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.92</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1973-02-28 01:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.92</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>1973-03-07 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>10.91</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-02 18:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.17</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-03 18:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.17</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-04 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.19</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-05 18:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.16</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-06 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.18</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-07 18:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.17</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-08 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.19</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-09 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.19</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-10 12:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.24</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-11 18:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.21</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-12 12:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.22</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-13 18:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.20</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-14 12:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.22</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-15 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.21</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-16 12:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.20</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-17 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.20</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-18 12:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.18</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5206</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-19 12:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.18</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5207</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-20 12:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.19</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5208</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-21 18:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.15</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5209</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-22 18:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.16</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-23 06:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.20</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-24 18:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.23</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5212</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-25 18:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.23</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-26 06:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.25</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-27 18:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.23</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-28 00:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.24</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-29 06:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.24</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-04-30 18:30</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.21</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>RN010167</td>\n",
       "      <td>2012-05-01 09:53</td>\n",
       "      <td>SWL</td>\n",
       "      <td>6.22</td>\n",
       "      <td>quality-A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5219 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Bore ID              Date Variable  Result (m) Quality Code\n",
       "0     RN010167  1972-04-12 01:30      SWL       10.98    quality-A\n",
       "1     RN010167  1972-04-19 00:30      SWL       10.98    quality-A\n",
       "2     RN010167        1972-04-26      SWL       10.98    quality-A\n",
       "3     RN010167        1972-05-03      SWL       10.97    quality-A\n",
       "4     RN010167  1972-05-10 00:30      SWL       10.97    quality-A\n",
       "5     RN010167  1972-05-17 00:30      SWL       10.96    quality-A\n",
       "6     RN010167  1972-05-24 00:30      SWL       10.97    quality-A\n",
       "7     RN010167  1972-06-28 00:30      SWL       10.97    quality-A\n",
       "8     RN010167  1972-07-05 00:30      SWL       10.98    quality-A\n",
       "9     RN010167  1972-07-17 00:30      SWL       11.00    quality-A\n",
       "10    RN010167  1972-07-19 00:30      SWL       11.00    quality-A\n",
       "11    RN010167  1972-07-26 00:30      SWL       10.99    quality-A\n",
       "12    RN010167        1972-08-02      SWL       11.00    quality-A\n",
       "13    RN010167  1972-08-09 00:30      SWL       11.00    quality-A\n",
       "14    RN010167  1972-08-16 00:30      SWL       11.00    quality-A\n",
       "15    RN010167  1972-09-27 00:30      SWL       11.00    quality-A\n",
       "16    RN010167        1972-10-04      SWL       10.97    quality-A\n",
       "17    RN010167  1972-10-11 00:30      SWL       10.97    quality-A\n",
       "18    RN010167  1972-10-18 00:30      SWL       10.95    quality-A\n",
       "19    RN010167  1972-11-15 01:30      SWL       10.95    quality-A\n",
       "20    RN010167  1972-11-22 01:30      SWL       10.93    quality-A\n",
       "21    RN010167  1973-01-10 01:30      SWL       10.93    quality-A\n",
       "22    RN010167  1973-01-17 01:30      SWL       10.92    quality-A\n",
       "23    RN010167  1973-01-24 01:30      SWL       10.92    quality-A\n",
       "24    RN010167  1973-01-31 01:00      SWL       10.92    quality-A\n",
       "25    RN010167  1973-02-07 01:30      SWL       10.93    quality-A\n",
       "26    RN010167  1973-02-14 01:30      SWL       10.92    quality-A\n",
       "27    RN010167  1973-02-21 01:00      SWL       10.92    quality-A\n",
       "28    RN010167  1973-02-28 01:30      SWL       10.92    quality-A\n",
       "29    RN010167  1973-03-07 00:30      SWL       10.91    quality-A\n",
       "...        ...               ...      ...         ...          ...\n",
       "5189  RN010167  2012-04-02 18:30      SWL        6.17    quality-A\n",
       "5190  RN010167  2012-04-03 18:30      SWL        6.17    quality-A\n",
       "5191  RN010167  2012-04-04 00:30      SWL        6.19    quality-A\n",
       "5192  RN010167  2012-04-05 18:30      SWL        6.16    quality-A\n",
       "5193  RN010167  2012-04-06 00:30      SWL        6.18    quality-A\n",
       "5194  RN010167  2012-04-07 18:30      SWL        6.17    quality-A\n",
       "5195  RN010167  2012-04-08 00:30      SWL        6.19    quality-A\n",
       "5196  RN010167  2012-04-09 00:30      SWL        6.19    quality-A\n",
       "5197  RN010167  2012-04-10 12:30      SWL        6.24    quality-A\n",
       "5198  RN010167  2012-04-11 18:30      SWL        6.21    quality-A\n",
       "5199  RN010167  2012-04-12 12:30      SWL        6.22    quality-A\n",
       "5200  RN010167  2012-04-13 18:30      SWL        6.20    quality-A\n",
       "5201  RN010167  2012-04-14 12:30      SWL        6.22    quality-A\n",
       "5202  RN010167  2012-04-15 00:30      SWL        6.21    quality-A\n",
       "5203  RN010167  2012-04-16 12:30      SWL        6.20    quality-A\n",
       "5204  RN010167  2012-04-17 00:30      SWL        6.20    quality-A\n",
       "5205  RN010167  2012-04-18 12:30      SWL        6.18    quality-A\n",
       "5206  RN010167  2012-04-19 12:30      SWL        6.18    quality-A\n",
       "5207  RN010167  2012-04-20 12:30      SWL        6.19    quality-A\n",
       "5208  RN010167  2012-04-21 18:30      SWL        6.15    quality-A\n",
       "5209  RN010167  2012-04-22 18:30      SWL        6.16    quality-A\n",
       "5210  RN010167  2012-04-23 06:30      SWL        6.20    quality-A\n",
       "5211  RN010167  2012-04-24 18:30      SWL        6.23    quality-A\n",
       "5212  RN010167  2012-04-25 18:30      SWL        6.23    quality-A\n",
       "5213  RN010167  2012-04-26 06:30      SWL        6.25    quality-A\n",
       "5214  RN010167  2012-04-27 18:30      SWL        6.23    quality-A\n",
       "5215  RN010167  2012-04-28 00:30      SWL        6.24    quality-A\n",
       "5216  RN010167  2012-04-29 06:30      SWL        6.24    quality-A\n",
       "5217  RN010167  2012-04-30 18:30      SWL        6.21    quality-A\n",
       "5218  RN010167  2012-05-01 09:53      SWL        6.22    quality-A\n",
       "\n",
       "[5219 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate \"percentage exceedance\" (perexc) for water level values\n",
    "all_data= all_data.rename(columns={'Result (m)':'waterlevel', 'Date':'date'})  #Rename flow and date columns\n",
    "all_data = all_data.sort_values('waterlevel', ascending=[False]) #Sort data by flow value\n",
    "all_data['rank'] = np.arange(len(all_data)) + 1 #Create rank column and values\n",
    "all_data['perexc'] = 100*(all_data['rank'])/(len(all_data)+1) #Calculate probability of each rank\n",
    "all_data= all_data.sort_values(['date']) #Sort data by date\n",
    "all_data['date']=pd.to_datetime(all_data['date'], format='%Y/%m/%d %H:%M:%S') #Change datetime format\n",
    "all_data.date = all_data.date.map(lambda t: t.strftime('%Y-%m-%d')) #Change datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return just the time and sensor product information from the Datacube extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product_time = nbar_clean[['time', 'product']].to_dataframe() #Add time and product to dataframe\n",
    "product_time.index = product_time.index + pd.Timedelta(hours=10) #Roughly convert to local time\n",
    "product_time.index = product_time.index.map(lambda t: t.strftime('%Y-%m-%d')) #Remove Hours/Minutes Seconds by formatting into a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match the date of stream flow data to the date where satellite information exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset_data = pd.merge(all_data, product_time, left_on= 'date', \n",
    "                       right_index=True, how='inner') #Match dates and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset_data['date']=pd.to_datetime(subset_data['date'], format='%Y/%m/%d %H:%M:%S') #Change datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create interactive bore hydrograph plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create date variables for axis on hydrograph plot to enable automatic axis scaling\n",
    "\n",
    "subset_dates = subset_data['date'] #Define matched dates\n",
    "all_dates=all_data['date']         #Define all dates\n",
    "\n",
    "min_date=min(subset_data.date) #Create minimum date value to enable automatic axis scaling\n",
    "max_date=max(subset_data.date) #Create maximum date value to enable automatic axis scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create flow variables for axis on hydrograph plot to enable automatic axis scaling\n",
    "\n",
    "max_waterlevel=max(subset_data.waterlevel) #Define maximum flow for matched flow\n",
    "min_waterlevel=min(subset_data.waterlevel) #Define minimum flow for matched flow\n",
    "\n",
    "min_waterlevel= (min_waterlevel-(0.01*max_waterlevel)) #Create minimum flow value to enable automatic axis scaling\n",
    "max_waterlevel= (max_waterlevel+(0.08*max_waterlevel)) #Create maximum flow value to enable automatic axis scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20170427/envs/agdc/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6340b29d1c9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create date variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msubset_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubset_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mall_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20170427/envs/agdc/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20170427/envs/agdc/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20170427/envs/agdc/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20170427/envs/agdc/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3543\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3544\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20170427/envs/agdc/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "#create date variables\n",
    "subset_dates = subset_data['date']\n",
    "all_dates=all_data['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create interactive hydrograph\n",
    "\n",
    "#create widget that enables interaction with hydrograph\n",
    "w = widgets.HTML(\"Event information appears here when you click on the figure\")\n",
    "def callback(event):\n",
    "    global time_int, discharge_int, devent\n",
    "    devent = event\n",
    "    time_int = event.xdata\n",
    "    discharge_int= event.ydata\n",
    "    time_int_ = time_int.astype(datetime64[D])\n",
    "    w.value = 'time_int: {}'.format(time_int)\n",
    "\n",
    "#Set up plot\n",
    "fig = plt.figure(figsize=(11.69,8.27)) #Edit size of plot ###User should format as required\n",
    "#fig = plt.figure(figsize=(10,10))  #Edit size of plot ###User should format if required\n",
    "fig.canvas.mpl_connect('button_press_event', callback) #Plot setup\n",
    "plt.title('Interactive bore hydrograph: '+bore_of_interest) #Plot title ###User should format if required\n",
    "plt.show() #Plot setup\n",
    "display(w) #Plot setup\n",
    "plt.subplots_adjust(left=0.12, right=0.95, top=0.95, bottom=0.15) #Set border dimensions  ###User should format if required\n",
    "fig.patch.set_facecolor('white') #Make border white ###User should format if required\n",
    "fig.patch.set_alpha(0.99) #Make border white ###User should format if required\n",
    "\n",
    "\n",
    "#plot\n",
    "matplotlib.pyplot.plot_date(all_dates,all_data['Result (m)'], '-', label= 'SWL')\n",
    "matplotlib.pyplot.plot_date(subset_dates, subset_data['Result (m)'], 'ro', label='SWL values with satellite imagery')\n",
    "\n",
    "#axis details\n",
    "firstyear = '1986-01-01'\n",
    "lastyear = '2014-12-30'\n",
    "plt.axis([firstyear , lastyear ,5, 11], 'tight')\n",
    "plt.xticks(rotation=45,size=10)\n",
    "plt.ylabel('SWL (m)')\n",
    "plt.xlabel('Date')\n",
    "plt.legend(edgecolor ='none', ncol=2, loc=9)\n",
    "plt.subplots_adjust(left=0.12, right=0.95, top=0.95, bottom=0.15)\n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.patch.set_alpha(0.99)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create interactive hydrograph\n",
    "\n",
    "#create widget that enables interaction with hydrograph\n",
    "w = widgets.HTML(\"Event information appears here when you click on the figure\")\n",
    "def callback(event):\n",
    "    global time_int, discharge_int, devent\n",
    "    devent = event\n",
    "    time_int = event.xdata\n",
    "    discharge_int= event.ydata\n",
    "    time_int_ = time_int.astype(datetime64[D])\n",
    "    w.value = 'time_int: {}'.format(time_int)\n",
    "\n",
    "#plot setup \n",
    "#fig = plt.figure(figsize=(10,10))\n",
    "fig = plt.figure(figsize=(11.69,8.27))\n",
    "fig.canvas.mpl_connect('button_press_event', callback)\n",
    "plt.title('Interactive bore hydrograph: ' + bore_of_interest )\n",
    "plt.show()\n",
    "display(w)\n",
    "\n",
    "#plot\n",
    "matplotlib.pyplot.plot_date(all_dates,all_data['Result (m)'], '-', label= 'SWL')\n",
    "matplotlib.pyplot.plot_date(subset_dates, subset_data['Result (m)'], 'ro', label='SWL values with satellite imagery')\n",
    "\n",
    "#axis details\n",
    "firstyear = '1986-01-01'\n",
    "lastyear = '2014-12-30'\n",
    "plt.axis([firstyear , lastyear ,5, 11], 'tight')\n",
    "plt.xticks(rotation=45,size=10)\n",
    "plt.ylabel('SWL (m)')\n",
    "plt.xlabel('Date')\n",
    "plt.legend(edgecolor ='none', ncol=2, loc=9)\n",
    "plt.subplots_adjust(left=0.12, right=0.95, top=0.95, bottom=0.15)\n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.patch.set_alpha(0.99)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #save figure\n",
    "%cd /g/data/r78/Geohack/Input/4_bore/\n",
    "plt.savefig('Hydrograph_'+bore_of_interest+'_all.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Discharge: ' + str(discharge_int) + ' m3'\n",
    "print 'Date as int: ' + str(time_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = matplotlib.dates.num2date(time_int).date()\n",
    "time_slice=str(time_slice)\n",
    "time_slice= pd.to_datetime(time_slice, format='%Y-%m-%d')\n",
    "subset_data['Date'] = pd.to_datetime(subset_data['Date'], format='%Y-%m-%d')\n",
    "subset_data['difference']=(subset_data['Date'] - time_slice).abs()\n",
    "time_slice=subset_data.ix[argsort(subset_data['difference'])].Date\n",
    "time_slice= (list(time_slice)[0])\n",
    "time_slice= str(time_slice)\n",
    "time_slice=datetime.datetime.strptime(time_slice,'%Y-%m-%d  %H:%M:%S')\n",
    "time_slice_actual=time_slice\n",
    "time_slice_t1=time_slice_actual+datetime.timedelta(days=-3)\n",
    "time_slice_t2=time_slice_actual+datetime.timedelta(days=3)\n",
    "\n",
    "# #Discharge\n",
    "# # discharge_title= subset_data.ix[argsort(subset_data['difference'])].'Result (m)'\n",
    "# # discharge_title= (list(discharge_title)[0])\n",
    "# # discharge_title= str(discharge_title)\n",
    "# # discharge_title2= float(discharge_title)\n",
    "# # discharge_title2=str(\"{0:.2f}\".format(discharge_title2))\n",
    "\n",
    "# #Percentage exceedance\n",
    "# perexc_title= subset_data.ix[argsort(subset_data['difference'])].perexc\n",
    "# perexc_title= (list(perexc_title)[0])\n",
    "# perexc_title= str(perexc_title)\n",
    "# perexc_title2= float(perexc_title)\n",
    "# perexc_title2=str(\"{0:.2f}\".format(perexc_title2))\n",
    "\n",
    "\n",
    "#Satellite\n",
    "satellite_type=subset_data.ix[argsort(subset_data['difference'])]\n",
    "satellite_type=satellite_type['product']\n",
    "satellite_type= (list(satellite_type)[0])\n",
    "satellite_type= str(satellite_type)\n",
    "satellite_type=  satellite_type.replace('pq','nbar')\n",
    "\n",
    "\n",
    "print 'Time 1:' +str(time_slice_t1)\n",
    "print 'Actual observation date: ' +str(time_slice_actual)\n",
    "print 'Time 2: ' +str(time_slice_t2)\n",
    "# print 'Discharge: ' +str(discharge_title2) +' m3'\n",
    "#print 'Percent exceedance: '+ str(perexc_title2) + '%'\n",
    "print 'Product: '+ str(satellite_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will work for time series that correspond with sensor1\n",
    "rgb = nbar_clean.sel(time =time_slice, method = 'nearest').to_array(dim='color').sel(color=['swir1', 'nir', 'green']).transpose('y', 'x', 'color')\n",
    "fake_saturation = 6000\n",
    "clipped_visible = rgb.where(rgb<fake_saturation).fillna(fake_saturation)\n",
    "max_val = clipped_visible.max(['y', 'x'])\n",
    "scaled2 = (clipped_visible / max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This image shows the time slice of choice and the location of the time series \n",
    "fig = plt.figure(figsize =(8,8))\n",
    "#plt.title('Gauge: '+gauge_of_interest +'    Date: '+str(time_slice_actual)[0:-9]  + '    Discharge: ' + discharge_title2+' $m^3$ $day^{-1}$' +\n",
    "#          '   Percentage exceedance: '+ str(perexc_title2) + '%', size=10)\n",
    "plt.scatter(x = [bh_x], y = [bh_y], c= 'r', marker = 'o', s=150)\n",
    "plt.imshow(scaled2, interpolation = 'nearest',\n",
    "           extent=[scaled2.coords['x'].min(), scaled2.coords['x'].max(), \n",
    "                  scaled2.coords['y'].min(), scaled2.coords['y'].max()])\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.patch.set_alpha(0.99)\n",
    "#remove axis \n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save figure\n",
    "%cd /g/data/r78/Geohack/Input/4_bore/\n",
    "plt.savefig('Hydrograph_'+ str(time_slice_actual)[0:-9] + '_' + bore_of_interest+'.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of large image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_of_epoch = time_slice_t1.strftime(\"%Y %m, %d\")\n",
    "end_of_epoch = time_slice_t2.strftime(\"%Y %m, %d\")\n",
    "\n",
    "query2 = {\n",
    "    'time': (start_of_epoch, end_of_epoch),\n",
    "}\n",
    "bands_of_interest = [#'blue',\n",
    "                     'green',\n",
    "                     #'red', \n",
    "                     'nir',\n",
    "                     'swir1', \n",
    "                     #'swir2'\n",
    "                     ]\n",
    "\n",
    "#Define sensors of interest, # out sensors that aren't relevant for the time period\n",
    "lat_max = bh_lat+ 0.6\n",
    "lat_min = bh_lat- 0.6\n",
    "lon_max = bh_long+ 0.15\n",
    "lon_min = bh_long- 0.8\n",
    "\n",
    "query2['x'] = (lon_min, lon_max)\n",
    "query2['y'] = (lat_max, lat_min)\n",
    "query2['crs'] = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    'ls8', #May 2013 to present\n",
    "    'ls7', #1999 to April 2003 (after this it'll have venetian blind artefacts caused by SLC off)\n",
    "    'ls5' #1987 to 1999 and then from April 2003 to 2011, \"\"\"\n",
    "    \n",
    "image_of_interest = dc.load(product= satellite_type, group_by='solar_day', measurements = bands_of_interest,  **query2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = image_of_interest.to_array(dim='color').sel(color=['swir1','nir', 'green']).squeeze().transpose('y', 'x', 'color')\n",
    "\n",
    "fake_saturation = 6000\n",
    "clipped_visible = rgb.where(rgb<fake_saturation).fillna(fake_saturation)\n",
    "max_val = clipped_visible.max(['y', 'x'])\n",
    "scaled = (clipped_visible / max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Create large image\n",
    "\n",
    "#fig = plt.figure(figsize =(21,21))\n",
    "fig = plt.figure(figsize =(10,10))\n",
    "\n",
    "#plt.title('Date: '+str(time_slice_actual)[0:-9]  + '    Flow: ' + discharge_title2+' $m^3$ $day^{-1}$',size=26)\n",
    "\n",
    "#plt.title('Gauge: '+gauge_of_interest +'    Date: '+str(time_slice_actual)[0:-9]  + '    Discharge: ' + discharge_title2+' $m^3$ $day^{-1}$' +\n",
    "#          '   Percentage exceedance: '+ str(perexc_title2) + '%', size=22)\n",
    "\n",
    "#plot imagery and add stream gauging location as marker\n",
    "plt.scatter(x = [bh_x], y = [bh_y], c= 'r', marker = 'o', s=100)\n",
    "\n",
    "plt.imshow(scaled, interpolation = 'nearest',\n",
    "           extent=[scaled.coords['x'].min(), scaled.coords['x'].max(), \n",
    "                  scaled.coords['y'].min(), scaled.coords['y'].max()])\n",
    "#reformat\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.patch.set_alpha(0.99)\n",
    "\n",
    "#remove axis \n",
    "plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save figure\n",
    "%cd /g/data/r78/Geohack/Input/4_bore/\n",
    "plt.savefig('Hydrograph_'+ str(time_slice_actual)[0:-9] +'_'+ bore_of_interest+'_large.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save as netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the original nbar dataset attributes (crs)\n",
    "#set up variable attributes to hold the attributes\n",
    "attrs = image_of_interest\n",
    "#get the band info\n",
    "bands = attrs.data_vars.keys()\n",
    "print bands\n",
    "for i in bands:\n",
    "    #drop band data, retaining just the attributes\n",
    "    attrs =attrs.drop(i)\n",
    "#set up new variable called ndvi_var, and assign attributes to it in a dictionary\n",
    "image_var = {'scaled':''}\n",
    "image_output = attrs.assign(**image_var)\n",
    "image_output['scaled'] = scaled\n",
    "print image_output\n",
    "image_output2 = image_output.scaled.to_dataset(dim='color')\n",
    "#print image_output\n",
    "image_output2.attrs['crs'] = image_output.crs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create net cdf\n",
    "outfile = '/g/data/r78/ext547/Output/netcdf/'+ str(time_slice_actual)[0:-9] +'.nc'\n",
    "write_dataset_to_netcdf(image_output2,  variable_params={'scaled': {'zlib':True}}, filename=outfile)\n",
    "print 'wrote: '+outfile+' to netcdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT_PROFILE = {\n",
    "#    'blockxsize': 256,\n",
    "#    'blockysize': 256,\n",
    "#    'compress': 'lzw',\n",
    "#    'driver': 'GTiff',\n",
    "#    'interleave': 'band',\n",
    "#    'nodata': 0.0,\n",
    "#    'photometric': 'RGBA',\n",
    "#    'tiled': True}\n",
    "\n",
    "\n",
    "# #this function definition comes from CK's Principal_Component_Analysis_AGDC_looped notebook, and before that from AGDC recipes.\n",
    "# def write_geotiff(filename, dataset, time_index=None, profile_override=None):\n",
    "#     \"\"\"\n",
    "#     Write an xarray dataset to a geotiff\n",
    "#     :attr bands: ordered list of dataset names\n",
    "#     :attr time_index: time index to write to file\n",
    "#     :attr dataset: xarray dataset containing multiple bands to write to file\n",
    "#     :attr profile_override: option dict, overrides rasterio file creation options.\n",
    "#     \"\"\"\n",
    "#     profile_override = profile_override or {}\n",
    "\n",
    "#     dtypes = {val.dtype for val in dataset.data_vars.values()}\n",
    "#     assert len(dtypes) == 1  # Check for multiple dtypes\n",
    "\n",
    "# #     profile = DEFAULT_PROFILE.copy()\n",
    "# #     profile.update({\n",
    "# #         'width': dataset.dims['x'],\n",
    "# #         'height': dataset.dims['y'],\n",
    "#         #'affine': dataset.affine, #changed following line 17/03/17 due to changes in AGDC I think\n",
    "#         'affine': dataset.affine,\n",
    "#         'crs': dataset.crs.crs_str,\n",
    "#         #'crs': dataset.crs,\n",
    "#         'count': len(dataset.data_vars),\n",
    "#         'dtype': str(dtypes.pop())\n",
    "#     })\n",
    "#     profile.update(profile_override)\n",
    "\n",
    "#     with rasterio.open(filename, 'w', **profile) as dest:\n",
    "#         for bandnum, data in enumerate(dataset.data_vars.values(), start=1):\n",
    "#             #dest.write(data.isel(time=time_index).data, bandnum)\n",
    "#             dest.write(data, bandnum)\n",
    "#             print ('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outfile = '/g/data/r78/ext547/Working/' + 'test' + '.tiff'\n",
    "# image_output2.attrs['crs'] = image_output.crs\n",
    "# write_geotiff(outfile, image_output2)\n",
    "# print 'tiff writing complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#est_output2.y[1] - test_output2.y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /g/data/r78/ext547/Working/\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gdalinfo test.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pq_fuser(dest, src):\n",
    "#     valid_bit = 8\n",
    "#     valid_val = (1 << valid_bit)\n",
    "#     no_data_dest_mask = ~(dest & valid_val).astype(bool)\n",
    "#     np.copyto(dest, src, where=no_data_dest_mask)\n",
    "#     both_data_mask = (valid_val & dest & src).astype(bool)\n",
    "#     np.copyto(dest, src & dest, where=both_data_mask)\n",
    "# indexers = {'time':('1991', '1992'), 'x':(lon_min, lon_max),   'y':(lat_min, lat_max), 'group_by':'solar_day'}\n",
    "# data = dc.load(product='ls5_nbar_albers', **indexers)\n",
    "# pq = dc.load(product='ls5_pq_albers', fuse_func=pq_fuser, **indexers)\n",
    "# mask_clear = pq['pixelquality'] & 15871 == 15871    # 15871 - This is a cloud free bits that includes land and sea bits\n",
    "# data = data.where(mask_clear)\n",
    "\n",
    "# from datacube.storage import masking\n",
    "# pq = dc.load(product='ls5_pq_albers', x=(lon_min, lon_max), y=(lat_min, lat_max), \n",
    "#              time=('1991', '1992'), group_by='solar_day')\n",
    "# # Make a mask for clouds\n",
    "# cloud_free = masking.make_mask(pq, cloud_acca='no_cloud', cloud_fmask='no_cloud', contiguous=True).pixelquality\n",
    "# # Find where at least 75% of the image is cloud free\n",
    "# mostly_cloud_free = cloud_free.mean(dim=('x','y')) > 0.75\n",
    "# # return only the NDVI times where there are no clouds\n",
    "# # dropna - return object with labels on given axis omitted where any/all the data are missing\n",
    "# #mostly_good_ndvi = ndvi.where(mostly_cloud_free).dropna('time', how='all')\n",
    "# #mostly_cloud_free.plot(col='time', col_wrap=3)\n",
    "# mostly_cloud_free = cloud_free.sum(dim=('x','y')) > (0.75 * data.green.size / data.time.size)\n",
    "# test = data.where(mostly_cloud_free).dropna('time', how='all')\n",
    "\n",
    "# print test.isel(time =1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "widgets": {
   "state": {
    "59eb3fccf8044fb88a44d9d3b72aa549": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
