{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Interactive flow curation curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This notebook creates an interactive flow duration curve. \n",
    "\n",
    "This notebook creates an interactive hydrograph that is used to return Earth observation images.\n",
    "Daily streamflow information and stream gauge coordinates are retrieved directly from the Bureau of Meteorology (BoM) Hydrologic Reference Stations (HRS) website, http://www.bom.gov.au/water/hrs/. The date of streamflow measurement and date of avaliable satellite imagery are matched, for the location of the gauge. \n",
    "\n",
    "A flow duration cuve plot is created that enables the user to click on any percentage exceedance value and return the closest satellite image, for a small area surrounding the location stream gauge. Further, a larger image is then returned and there is an option to save imagery as a netcdf file.\n",
    "\n",
    "\"###\" indicates fields that require user modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-09T11:09:06.502514",
     "start_time": "2016-06-09T11:09:04.805211"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "%pylab notebook\n",
    "\n",
    "import datacube\n",
    "from datacube.storage import masking\n",
    "from datacube.storage.masking import mask_to_dict\n",
    "from datacube.storage.storage import write_dataset_to_netcdf\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import rasterio\n",
    "import urllib\n",
    "from pyproj import Proj, transform\n",
    "from dateutil import tz\n",
    "from_zone = tz.tzutc()\n",
    "to_zone = tz.tzlocal()\n",
    "dc = datacube.Datacube(app='dc-show changes in annual mean NDVI values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Retrieve the stream gauge data and coordinates from the BoM website\n",
    "The URL for the data is set using the gauge_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Specify stream gauge of interest.\n",
    "\n",
    "### Enter the ID code for the gauge of interest. ID code can be viewed on http://www.bom.gov.au/water/hrs/\n",
    "### e.g. for 'Diamantina River at Birdsville' the ID code is 'A0020101'\n",
    "\n",
    "gauge_of_interest= 'A0020101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date  Flow (ML) Bureau QCode\n",
      "0      1966-10-19     0.0000            A\n",
      "1      1966-10-20     0.0000            A\n",
      "2      1966-10-21     0.0000            A\n",
      "3      1966-10-22     0.0000            A\n",
      "4      1966-10-23     0.0000            A\n",
      "5      1966-10-24     0.0000            A\n",
      "6      1966-10-25     0.0000            A\n",
      "7      1966-10-26     0.0000            A\n",
      "8      1966-10-27     0.0000            A\n",
      "9      1966-10-28     0.0000            A\n",
      "10     1966-10-29     0.0000            A\n",
      "11     1966-10-30     0.0000            A\n",
      "12     1966-10-31     0.0000            A\n",
      "13     1966-11-01     0.0000            A\n",
      "14     1966-11-02     0.0000            A\n",
      "15     1966-11-03     0.0000            A\n",
      "16     1966-11-04     0.0000            A\n",
      "17     1966-11-05     0.0000            A\n",
      "18     1966-11-06     0.0000            A\n",
      "19     1966-11-07     0.0000            A\n",
      "20     1966-11-08     0.0000            A\n",
      "21     1966-11-09     0.0000            A\n",
      "22     1966-11-10     0.0000            A\n",
      "23     1966-11-11     0.0000            A\n",
      "24     1966-11-12     0.0000            A\n",
      "25     1966-11-13     0.0000            A\n",
      "26     1966-11-14    66.3815            A\n",
      "27     1966-11-15   162.4570            A\n",
      "28     1966-11-16   136.3770            A\n",
      "29     1966-11-17   106.1850            A\n",
      "...           ...        ...          ...\n",
      "17576  2014-12-02     0.0000            E\n",
      "17577  2014-12-03     0.0000            E\n",
      "17578  2014-12-04     0.0000            E\n",
      "17579  2014-12-05     0.0000            E\n",
      "17580  2014-12-06     0.0000            E\n",
      "17581  2014-12-07     0.0000            E\n",
      "17582  2014-12-08     0.0000            E\n",
      "17583  2014-12-09     0.0000            E\n",
      "17584  2014-12-10     0.0000            E\n",
      "17585  2014-12-11     0.0000            E\n",
      "17586  2014-12-12     0.0000            E\n",
      "17587  2014-12-13     0.0000            E\n",
      "17588  2014-12-14     0.0000            E\n",
      "17589  2014-12-15     0.0000            E\n",
      "17590  2014-12-16     0.0000            E\n",
      "17591  2014-12-17     0.0000            E\n",
      "17592  2014-12-18     0.0000            E\n",
      "17593  2014-12-19     0.0000            E\n",
      "17594  2014-12-20     0.0000            E\n",
      "17595  2014-12-21     0.0000            E\n",
      "17596  2014-12-22     0.0000            E\n",
      "17597  2014-12-23     0.0000            E\n",
      "17598  2014-12-24     0.0000            E\n",
      "17599  2014-12-25  1564.8200            E\n",
      "17600  2014-12-26  2021.5500            E\n",
      "17601  2014-12-27  2109.8700            E\n",
      "17602  2014-12-28  2186.4100            E\n",
      "17603  2014-12-29  2231.4000            E\n",
      "17604  2014-12-30  2233.9000            E\n",
      "17605  2014-12-31  2249.5000            E\n",
      "\n",
      "[17606 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Url is used to retrieve daily streamflow data for the gauge_of_interest    \n",
    "url = 'http://www.bom.gov.au/water/hrs/content/data/'+gauge_of_interest+'/'+gauge_of_interest+'_daily_ts.csv'\n",
    "gaugedata = pd.read_csv(url, comment='#')\n",
    "print (gaugedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographic: 139.3667, -25.9088\n",
      "Australian Albers: 728893.3995514876, -2825460.0787998526\n"
     ]
    }
   ],
   "source": [
    "# Url is used to retrieve stream gauge location coordinates. Coordinates are reprojected to Australian Albers    \n",
    "\n",
    "#Search url to find coordinates \n",
    "coord_txt = urllib.request.urlopen(url).read()\n",
    "coord_txt = str(coord_txt)\n",
    "sg_lon = coord_txt.split('\"Location:\", ')[1].split(',\"degrees E\",')[0]\n",
    "sg_lon=float(sg_lon)\n",
    "sg_lat = coord_txt.split(',\"degrees E\", ')[1].split(',\"degrees S\"')[0]\n",
    "sg_lat= \"-\"+sg_lat\n",
    "sg_lat=float(sg_lat)\n",
    "\n",
    "#Reproject\n",
    "inProj = Proj(init='EPSG:4326')\n",
    "outProj = Proj(init='EPSG:3577')\n",
    "sg_x,sg_y = transform(inProj,outProj,sg_lon,sg_lat)\n",
    "\n",
    "print (\"Geographic: \" + str(sg_lon)+', '+ str(sg_lat))\n",
    "print (\"Australian Albers: \"+ str(sg_x)+', '+str(sg_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Complete Datacube query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Spatiotemporal range and wavelengths/band of interest are defined\n",
    "\n",
    "# Define temporal range\n",
    "start_of_epoch = '1987-01-01'\n",
    "end_of_epoch =  '2014-12-31'\n",
    "\n",
    "# Define wavelengths/bands of interest\n",
    "bands_of_interest = ['green',\n",
    "                     'red', \n",
    "                     'nir',\n",
    "                     'swir1']\n",
    "\n",
    "# Define sensors of interest\n",
    "sensors = ['ls8',\n",
    "    'ls7',\n",
    "    'ls5' ] \n",
    "\n",
    "# Create bounding box around the location of the stream gauge\n",
    "lat_max = sg_lat + 0.05\n",
    "lat_min = sg_lat - 0.05\n",
    "lon_max = sg_lon + 0.05\n",
    "lon_min = sg_lon - 0.05\n",
    "\n",
    "# Create query\n",
    "query = {'time': (start_of_epoch, end_of_epoch)}\n",
    "query['x'] = (lon_min, lon_max)\n",
    "query['y'] = (lat_max, lat_min)\n",
    "query['crs'] = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create cloud mask. This will define which pixel quality (PQ) artefacts are removed from the results.\n",
    "\n",
    "mask_components = {'cloud_acca':'no_cloud',\n",
    "'cloud_shadow_acca' :'no_cloud_shadow',\n",
    "'cloud_shadow_fmask' : 'no_cloud_shadow',\n",
    "'cloud_fmask' :'no_cloud',\n",
    "'blue_saturated' : False,\n",
    "'green_saturated' : False,\n",
    "'red_saturated' : False,\n",
    "'nir_saturated' : False,\n",
    "'swir1_saturated' : False,\n",
    "'swir2_saturated' : False,\n",
    "'contiguous':True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Datacube extraction\n",
    "The extracted data is first filtered using the criteria in \"mask_components\".\n",
    "The cloudyness of the scenes is then tested, and any scenes that do not meet the given \"cloud_threshold\" are discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded ls8\n",
      "loaded ls7\n",
      "loaded ls5\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "#Retrieve the NBAR and PQ data for sensor n\n",
    "sensor_clean = {}\n",
    "cloud_threshold = 0.10\n",
    "for sensor in sensors:\n",
    "    #Load the NBAR and corresponding PQ\n",
    "    sensor_nbar = dc.load(product= sensor+'_nbar_albers', group_by='solar_day', measurements = bands_of_interest,  **query)\n",
    "    sensor_pq = dc.load(product= sensor+'_pq_albers', group_by='solar_day', fuse_func=ga_pq_fuser, **query)\n",
    "    \n",
    "    #grab the projection info before masking/sorting\n",
    "    crs = sensor_nbar.crs\n",
    "    crswkt = sensor_nbar.crs.wkt\n",
    "    affine = sensor_nbar.affine\n",
    "    \n",
    "    #This line is to make sure there's PQ to go with the NBAR\n",
    "    sensor_nbar = sensor_nbar.sel(time = sensor_pq.time)\n",
    "    \n",
    "    #Apply the PQ masks to the NBAR\n",
    "    quality_mask = masking.make_mask(sensor_pq, **mask_components)\n",
    "    good_data = quality_mask.pixelquality.loc[start_of_epoch:end_of_epoch]\n",
    "    sensor_nbar2 = sensor_nbar.where(good_data)\n",
    "    \n",
    "    # Calculate the percentage cloud free for each scene\n",
    "    cloud_free = masking.make_mask(sensor_pq, cloud_acca='no_cloud', cloud_fmask='no_cloud', contiguous=True).pixelquality\n",
    "    mostly_cloud_free = cloud_free.mean(dim=('x','y')) >= cloud_threshold\n",
    "        \n",
    "    # Throw away data that does not meet the cloud_threshold\n",
    "    mostly_good = sensor_nbar2.where(mostly_cloud_free).dropna(dim='time', how='all')\n",
    "    mostly_good['product'] = ('time', numpy.repeat(sensor, mostly_good.time.size))    \n",
    "    sensor_clean[sensor] = mostly_good\n",
    "\n",
    "    print('loaded %s' % sensor) \n",
    "    \n",
    "\n",
    "print ('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ls5': <xarray.Dataset>\n",
       " Dimensions:  (time: 336, x: 422, y: 471)\n",
       " Coordinates:\n",
       "   * time     (time) datetime64[ns] 1987-05-22T00:01:19.500000 ...\n",
       "   * y        (y) float64 -2.82e+06 -2.82e+06 -2.82e+06 -2.82e+06 -2.82e+06 ...\n",
       "   * x        (x) float64 7.236e+05 7.237e+05 7.237e+05 7.237e+05 7.237e+05 ...\n",
       " Data variables:\n",
       "     green    (time, y, x) float64 1.571e+03 1.571e+03 1.632e+03 1.571e+03 ...\n",
       "     red      (time, y, x) float64 2.364e+03 2.417e+03 2.47e+03 2.47e+03 ...\n",
       "     nir      (time, y, x) float64 2.992e+03 2.992e+03 3.12e+03 3.056e+03 ...\n",
       "     swir1    (time, y, x) float64 3.842e+03 3.976e+03 4.11e+03 4.066e+03 ...\n",
       "     product  (time) <U3 'ls5' 'ls5' 'ls5' 'ls5' 'ls5' 'ls5' 'ls5' 'ls5' ...\n",
       " Attributes:\n",
       "     crs: EPSG:3577, 'ls7': <xarray.Dataset>\n",
       " Dimensions:  (time: 293, x: 422, y: 471)\n",
       " Coordinates:\n",
       "   * time     (time) datetime64[ns] 1999-07-18T00:30:07.500000 ...\n",
       "   * y        (y) float64 -2.82e+06 -2.82e+06 -2.82e+06 -2.82e+06 -2.82e+06 ...\n",
       "   * x        (x) float64 7.236e+05 7.237e+05 7.237e+05 7.237e+05 7.237e+05 ...\n",
       " Data variables:\n",
       "     green    (time, y, x) float64 1.449e+03 1.517e+03 1.753e+03 1.652e+03 ...\n",
       "     red      (time, y, x) float64 2.594e+03 2.77e+03 2.945e+03 2.887e+03 ...\n",
       "     nir      (time, y, x) float64 3.162e+03 3.333e+03 3.633e+03 3.505e+03 ...\n",
       "     swir1    (time, y, x) float64 4.324e+03 4.517e+03 4.749e+03 4.672e+03 ...\n",
       "     product  (time) <U3 'ls7' 'ls7' 'ls7' 'ls7' 'ls7' 'ls7' 'ls7' 'ls7' ...\n",
       " Attributes:\n",
       "     crs: EPSG:3577, 'ls8': <xarray.Dataset>\n",
       " Dimensions:  (time: 34, x: 422, y: 471)\n",
       " Coordinates:\n",
       "   * time     (time) datetime64[ns] 2013-04-01T00:42:01.500000 ...\n",
       "   * y        (y) float64 -2.82e+06 -2.82e+06 -2.82e+06 -2.82e+06 -2.82e+06 ...\n",
       "   * x        (x) float64 7.236e+05 7.237e+05 7.237e+05 7.237e+05 7.237e+05 ...\n",
       " Data variables:\n",
       "     green    (time, y, x) float64 1.314e+03 1.38e+03 1.443e+03 1.389e+03 ...\n",
       "     red      (time, y, x) float64 2.4e+03 2.481e+03 2.521e+03 2.458e+03 ...\n",
       "     nir      (time, y, x) float64 3.035e+03 3.13e+03 3.173e+03 3.112e+03 ...\n",
       "     swir1    (time, y, x) float64 4.275e+03 4.347e+03 4.399e+03 4.339e+03 ...\n",
       "     product  (time) <U3 'ls8' 'ls8' 'ls8' 'ls8' 'ls8' 'ls8' 'ls8' 'ls8' ...\n",
       " Attributes:\n",
       "     crs: EPSG:3577}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the output to make sure we have what we think we have\n",
    "sensor_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ccf535b6d968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Concatenate data from different sensors together and sort so that observations are sorted by time rather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# than sensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnbar_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensor_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtime_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbar_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnbar_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbar_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20170327/envs/agdc/lib/python3.5/site-packages/xarray/core/combine.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, indexers, mode, concat_over)\u001b[0m\n\u001b[1;32m    118\u001b[0m         raise TypeError('can only concatenate xarray Dataset and DataArray '\n\u001b[1;32m    119\u001b[0m                         'objects, got %s' % type(first_obj))\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20170327/envs/agdc/lib/python3.5/site-packages/xarray/core/combine.py\u001b[0m in \u001b[0;36m_dataset_concat\u001b[0;34m(datasets, dim, data_vars, coords, compat, positions)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcat_over\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_common_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0minsert_result_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20170327/envs/agdc/lib/python3.5/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(variables, dim, positions, shortcut)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndexVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20170327/envs/agdc/lib/python3.5/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(cls, variables, dim, positions, shortcut)\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_axis_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpositions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0;31m# TODO: deprecate this option -- we don't need it for groupby\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data/v10/public/modules/agdc-py3-env/20170327/envs/agdc/lib/python3.5/site-packages/xarray/core/ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meager_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Concatenate data from different sensors together and sort so that observations are sorted by time rather\n",
    "# than sensor\n",
    "nbar_clean = xr.concat(sensor_clean.values(), dim='time')\n",
    "time_sorted = nbar_clean.time.argsort()\n",
    "nbar_clean = nbar_clean.isel(time=time_sorted)\n",
    "nbar_clean.attrs['crs'] = crs\n",
    "nbar_clean.attrs['affin|e'] = affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Check that the concat worked\n",
    "nbar_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Process stream gauge information\n",
    "Calculate the percentiles of stream flow, and sort the dataframe according to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import streamflow data from the gauge of interest\n",
    "all_data = gaugedata\n",
    "all_data= all_data.rename(columns={'Flow (ML)':'flow', 'Date':'date'})\n",
    "all_data['order'] = np.arange(len(all_data)) + 1\n",
    "#sort data by flow\n",
    "all_data = all_data.sort_values('flow', ascending=[False])\n",
    "#create rank column and data\n",
    "all_data['ranks'] = np.arange(len(all_data)) + 1\n",
    "# calculate probability of each rank\n",
    "all_data['perexc'] = 100*(all_data['ranks'])/(len(all_data)+1)\n",
    "all_data= all_data.sort_values(['order'])\n",
    "all_data=all_data.drop(all_data.columns[[2]], axis=1)\n",
    "all_data['date']=pd.to_datetime(all_data['date'], format='%Y/%m/%d %H:%M:%S')\n",
    "all_data.date = all_data.date.map(lambda t: t.strftime('%Y-%m-%d')) # convert to a str for the merge below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Return just the time and sensor product information from the datacube extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "product_time = nbar_clean[['time', 'product']].to_dataframe()\n",
    "product_time.index = product_time.index + pd.Timedelta(hours=10) # Roughly convert to local time\n",
    "product_time.index = product_time.index.map(lambda t: t.strftime('%Y-%m-%d')) # Remove Hours/Minutes Seconds by formatting into a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Find where both stream gauge data AND satellite information exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subset_data = pd.merge(all_data, product_time, left_on= 'date', right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "subset_data['date']=pd.to_datetime(subset_data['date'], format='%Y/%m/%d %H:%M:%S') # back to datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create interactive flow duration curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##Prepare datasets for FDC\n",
    "\n",
    "#Preapre all data\n",
    "sorted_a_flow=sorted(all_data.flow, reverse=True)\n",
    "sorted_a_pe=sorted(all_data.perexc)\n",
    "\n",
    "#Prepare the matched subset data\n",
    "sorted_s_flow=sorted(subset_data.flow, reverse=True)\n",
    "sorted_s_pe=sorted(subset_data.perexc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##create interactive flow duration curve\n",
    "\n",
    "w = widgets.HTML(\"Click on a point on the curve to display the satellite image\")\n",
    "def callback(event):\n",
    "    global discharge_int, perexc_int, devent\n",
    "    devent = event\n",
    "    discharge_int = event.ydata\n",
    "    perexc_int = event.xdata\n",
    "    discharge_int = discharge_int.astype(datetime64[D])\n",
    "    w.value = 'time_int: {}'.format(time_int)\n",
    "\n",
    "\n",
    "#Plot details\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.canvas.mpl_connect('button_press_event', callback)\n",
    "plt.title('Interactive flow duration curve: '+gauge_of_interest)\n",
    "display(w)\n",
    "\n",
    "#create plot of percent exceedance\n",
    "plt.plot(sorted_a_pe,sorted_a_flow,'o',label= 'All discharge values')\n",
    "plt.plot(sorted_s_pe,sorted_s_flow,'ro',label='Discharge values with suitable satellite imagery')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "#axis and legend details\n",
    "plt.axis([-5, 105, 0.0001, 1000000])\n",
    "plt.xticks(rotation=45,size=10)\n",
    "plt.ylabel('Discharge (m$^3$ day$^{-1}$)')\n",
    "plt.xlabel('Percentage of time equalled or exceeded (%)')\n",
    "pyplot.yscale('log')\n",
    "plt.legend(edgecolor ='none', ncol=2, loc=9)\n",
    "plt.subplots_adjust(left=0.10, right=0.96, top=0.95, bottom=0.12)\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.patch.set_alpha(0.99)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#save figure\n",
    "%cd /g/data/r78/ext547/Output/FDC/\n",
    "plt.savefig('FDC_'+gauge_of_interest+'_10pct_CFI.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'discharge_int' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3a0782c7f1b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Discharge: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdischarge_int\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' m3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Percentage Exceedance: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperexc_int\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m' %'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'discharge_int' is not defined"
     ]
    }
   ],
   "source": [
    "print ('Discharge: ' + str(discharge_int) + ' m3')\n",
    "print ('Percentage Exceedance: ' + str(perexc_int) +' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Find the closest percentile to the clicked point; find exact date, discharge or percentage exceedance \n",
    "# value; and format for graph title.\n",
    "\n",
    "#Date\n",
    "time_slice=subset_data.iloc[(subset_data.perexc - perexc_int).abs().argsort()[0:1]].date\n",
    "time_slice= (list(time_slice)[0])\n",
    "time_slice= str(time_slice) \n",
    "time_slice=datetime.datetime.strptime(time_slice,'%Y-%m-%d %H:%M:%S')\n",
    "time_slice_actual=time_slice\n",
    "time_slice_t1=time_slice_actual + datetime.timedelta(days=-2)\n",
    "time_slice_t2=time_slice_actual + datetime.timedelta(days=2)\n",
    "\n",
    "#Discharge \n",
    "discharge_title=subset_data.iloc[(subset_data.perexc - perexc_int).abs().argsort()[:1]].flow\n",
    "discharge_title2= float(discharge_title)\n",
    "discharge_title2=str(\"{0:.2f}\".format(discharge_title2))\n",
    "\n",
    "#Percentage exceedance\n",
    "perexc_title=subset_data.iloc[(subset_data.perexc - perexc_int).abs().argsort()[:1]].perexc\n",
    "perexc_title2= float(perexc_title)\n",
    "perexc_title2=str(\"{0:.2f}\".format(perexc_title2))\n",
    "\n",
    "#Satellite\n",
    "satellite_type=subset_data.iloc[(subset_data.perexc - perexc_int).abs().argsort()[:1]]\n",
    "satellite_type=satellite_type['product']\n",
    "satellite_type= (list(satellite_type)[0])\n",
    "satellite_type= str(satellite_type)+'_nbar_albers'\n",
    "\n",
    "\n",
    "print ('Time 1:' +str(time_slice_t1))\n",
    "print ('Actual observation date: ' +str(time_slice_actual))\n",
    "print ('Time 2: ' +str(time_slice_t2))\n",
    "print ('Discharge: ' +str(discharge_title2) +' m3')\n",
    "print ('Perexc_int: ' +str(perexc_int) +'%')\n",
    "print ('Percent exceedance: '+ str(perexc_title2) + '%')\n",
    "print ('Product: '+ str(satellite_type)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##create  flow duration curve showing date of interest\n",
    "\n",
    "#Plot details\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.canvas.mpl_connect('button_press_event', callback)\n",
    "plt.title('Interactive flow duration curve: '+gauge_of_interest)\n",
    "display(w)\n",
    "\n",
    "#create plot of percent exceedance\n",
    "plt.plot(sorted_a_pe,sorted_a_flow,'o',label= 'All discharge values')\n",
    "plt.plot(sorted_s_pe,sorted_s_flow,'ro',label='Discharge values with suitable satellite imagery')\n",
    "plt.plot(perexc_title2,discharge_title2, 'ko', label='Event of interest',ms=10)\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "#axis and legend details\n",
    "plt.axis([-5, 105, 0.0001, 1000000])\n",
    "plt.xticks(rotation=45,size=10)\n",
    "plt.ylabel('Discharge (m$^3$ day$^{-1}$)')\n",
    "plt.xlabel('Percentage of time equalled or exceeded (%)')\n",
    "pyplot.yscale('log')\n",
    "plt.legend(edgecolor ='none', ncol=1, loc=9)\n",
    "plt.subplots_adjust(left=0.10, right=0.96, top=0.95, bottom=0.12)\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.patch.set_alpha(0.99)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#save figure\n",
    "%cd /g/data/r78/ext547/Output/FDC/\n",
    "# save image with date of interest\n",
    "plt.savefig('FDC_'+gauge_of_interest+'_PE'+str(perexc_title2)+'.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Creation of small image directly around stream gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Prepare imagery\n",
    "rgb = nbar_clean.sel(time =time_slice_actual, method = 'nearest').to_array(dim='color').sel(color=['swir1','nir', 'green']).transpose('y', 'x', 'color')\n",
    "fake_saturation = 6000.0\n",
    "rgb = rgb.astype('double')\n",
    "clipped_visible = rgb.where(rgb<fake_saturation).fillna(fake_saturation)\n",
    "max_val = clipped_visible.max(['y', 'x'])\n",
    "scaled = (clipped_visible / max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This image shows the time slice of choice and the location of the time series \n",
    "fig = plt.figure(figsize =(8,8))\n",
    "plt.title('Gauge: '+gauge_of_interest +'   Date: '+str(time_slice_actual)[0:-9]  + '    Discharge: ' + discharge_title2+' $m^3$ $day^{-1}$' +\n",
    "          '   Percentage exceedance: '+ str(perexc_title2) + '%', size=10)\n",
    "plt.scatter(x = [sg_x], y = [sg_y], c= 'r', marker = 'o', s=150)\n",
    "plt.imshow(scaled, interpolation = 'nearest',\n",
    "           extent=[scaled.coords['x'].min(), scaled.coords['x'].max(), \n",
    "                  scaled.coords['y'].min(), scaled.coords['y'].max()])\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.patch.set_alpha(0.99)\n",
    "#remove axis \n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#save figure\n",
    "%cd /g/data/r78/ext547/Output/FDC/\n",
    "plt.savefig('FDC_'+gauge_of_interest+'_PE'+ str(perexc_title2) + '_D'+str(discharge_title2)+'_'+ str(time_slice_actual)[0:-9] +'_small'+ '.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Creation of large image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "start_of_epoch = time_slice_t1.strftime(\"%Y %m, %d\")\n",
    "end_of_epoch = time_slice_t2.strftime(\"%Y %m, %d\")\n",
    "\n",
    "query2 = {\n",
    "    'time': (start_of_epoch, end_of_epoch),\n",
    "}\n",
    "bands_of_interest = [#'blue',\n",
    "                     'green',\n",
    "                     #'red', \n",
    "                     'nir',\n",
    "                     'swir1', \n",
    "                     #'swir2'\n",
    "                     ]\n",
    "\n",
    "#Define sensors of interest, # out sensors that aren't relevant for the time period\n",
    "lat_max = sg_lat+ 0.6\n",
    "lat_min = sg_lat- 0.6\n",
    "lon_max = sg_lon+ 0.8\n",
    "lon_min = sg_lon- 0.4\n",
    "\n",
    "query2['x'] = (lon_min, lon_max)\n",
    "query2['y'] = (lat_max, lat_min)\n",
    "query2['crs'] = 'EPSG:4326'\n",
    "print (query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    'ls8', #May 2013 to present\n",
    "    'ls7', #1999 to April 2003 (after this it'll have venetian blind artefacts caused by SLC off)\n",
    "    'ls5' #1987 to 1999 and then from April 2003 to 2011, \"\"\"\n",
    "    \n",
    "image_of_interest = dc.load(product= satellite_type, group_by='solar_day', measurements = bands_of_interest,  **query2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rgb2 = image_of_interest.to_array(dim='color').sel(color=['swir1','nir', 'green']).squeeze().transpose('y', 'x', 'color')\n",
    "fake_saturation = 6000\n",
    "clipped_visible = rgb2.where(rgb2<fake_saturation).fillna(fake_saturation)\n",
    "max_val = clipped_visible.max(['y', 'x'])\n",
    "scaled = (clipped_visible / max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Create large image\n",
    "\n",
    "fig = plt.figure(figsize =(21,21))\n",
    "plt.title('Gauge: '+gauge_of_interest +'    Date: '+str(time_slice_actual)[0:-9]  + '    Discharge: ' + discharge_title2+' $m^3$ $day^{-1}$' +\n",
    "          '   Percentage exceedance: '+ str(perexc_title2) + '%', size=22)\n",
    "#plot imagery and add stream gauging location as marker\n",
    "plt.scatter(x = [sg_x], y = [sg_y], c= 'r', marker = 'o', s=500)\n",
    "plt.imshow(scaled, interpolation = 'nearest',\n",
    "           extent=[scaled.coords['x'].min(), scaled.coords['x'].max(), \n",
    "                  scaled.coords['y'].min(), scaled.coords['y'].max()])\n",
    "#reformat\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.patch.set_alpha(0.99)\n",
    "#remove axis \n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#save figure\n",
    "%cd /g/data/r78/ext547/Output/FDC/\n",
    "plt.savefig('FDC_'+gauge_of_interest+'_PE'+ str(perexc_title2) + '_D'+str(discharge_title2)+'_'+ str(time_slice_actual)[0:-9] +'_large'+ '.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Save as netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get the original nbar dataset attributes (crs)\n",
    "#set up variable attributes to hold the attributes\n",
    "attrs = image_of_interest\n",
    "#get the band info\n",
    "bands = attrs.data_vars.keys()\n",
    "print (bands)\n",
    "for i in bands:\n",
    "    #drop band data, retaining just the attributes\n",
    "    attrs =attrs.drop(i)\n",
    "#set up new variable called ndvi_var, and assign attributes to it in a dictionary\n",
    "image_var = {'scaled':''}\n",
    "image_output = attrs.assign(**image_var)\n",
    "image_output['scaled'] = scaled\n",
    "print (image_output)\n",
    "image_output2 = image_output.scaled.to_dataset(dim='color')\n",
    "#print image_output\n",
    "image_output2.attrs['crs'] = image_output.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## create net cdf\n",
    "outfile = '/g/data/r78/ext547/Output/netcdf/'+ str(time_slice_actual)[0:-9] +'.nc'\n",
    "write_dataset_to_netcdf(image_output2,  variable_params={'scaled': {'zlib':True}}, filename=outfile)\n",
    "print ('wrote: '+outfile+' to netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_threshold": 6,
   "toc_window_display": true
  },
  "widgets": {
   "state": {
    "6dc82a33fe67407293537fd5b961062a": {
     "views": [
      {
       "cell_index": 25
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
